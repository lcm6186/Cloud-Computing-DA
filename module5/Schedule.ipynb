{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 - Amazon Web Services, part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Topics\n",
    "\n",
    "* Elastic Map Reduce(EMR)\n",
    "* Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readings\n",
    "\n",
    "\n",
    "  * [AWS EMR documentation](http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-overview.html)\n",
    "  * [Machine Learning with Spark](https://web.dsa.missouri.edu/static/PDF/MACHINE_LEARNING_WITH_SPARK.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labs\n",
    "\n",
    "**Note**: The labs will have specific containers noted by their headings.\n",
    "\n",
    "#### AWS Container  \n",
    "\n",
    "  * [EMR Cluster Deployment](labs/EMR_Cluster_Deployment.ipynb)\n",
    "  \n",
    "#### AWS Web Console\n",
    "\n",
    "  * [EMR Web Console Walkthrough (PDF)](labs/emr-web-console-walkthrough.pdf)\n",
    "    * If PDF does not open in a browser tab, try to _Right Click > Save As ..._\n",
    "    \n",
    "\n",
    "#### Allspark Container  \n",
    "The *Allspark* container encapsulates a Spark Cluster into a local notebook for small case learning examples.  \n",
    "You the container is located here: https://hub.docker.com/r/jupyter/all-spark-notebook/  \n",
    "Refer back to Day 1, Lab Jupyter from Docker, but this time instatiate the Allspark container.\n",
    "Once you have the container running, upload the following notebook to run in your Allspark container in AWS.\n",
    "  \n",
    "  * [PySpark](labs/PySpark_Reddit_Comments.ipynb)\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice (use _Allspark_ container you deployed on AWS)\n",
    "\n",
    " \n",
    "#### <span style='background:yellow'>Similar to earlier module, message the TA on Slack or Email to review your running notebook.</span>  After it has been verified, you may shut the container down.\n",
    "\n",
    "  * [PySpark](practices/Practice_PySpark.ipynb)\n",
    "  \n",
    "\n",
    "## AWS Project (Exercise)\n",
    "\n",
    "  * [AWS Architect Project](exercises/AWS_Architect_Project.ipynb)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting your work\n",
    "\n",
    "#### Steps:\n",
    "  1. Open Terminal in JupyterHub\n",
    "  1. Change into the course folder\n",
    "  1. Stage (Git Add) the module's practive and exercise work   \n",
    "  `git  add   module5/labs    module5/practices    module5/exercises`\n",
    "  1. Create your work snapshot (Git Commit)  \n",
    "  `git   commit   -m   \"Module 5 submission\"`\n",
    "  1. Upload the snapshot to the server (Git Push)  \n",
    "  `git   push`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, you have completed the learning activities for this module!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
