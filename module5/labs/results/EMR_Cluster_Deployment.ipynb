{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS EMR Launcher\n",
    "Welcome to the DSA Hadoop Launcher. Here you will add your key and a couple paramaters to deploy your own Hadoop stack on AWS.\n",
    "\n",
    "Please set the paramaters in the \"SET THE FOLLOWING PARAMETERS\" box below and run the first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch an EMR cluster with a Jupyter Notebook\n",
    "\n",
    "################################### SET THE FOLLOWING PARAMETERS ###################################################\n",
    "#Set the AWS Region\n",
    "region = 'us-west-2'\n",
    "\n",
    "#Set the AWS Access ID (Given to you buy the DSA staff)\n",
    "access_id = 'AKIA2M4ITY7JQWGANH3B'\n",
    "\n",
    "#Set the AWS Access Key (Given to you buy the DSA staff)\n",
    "access_key = 'PehA8Lji/KXz7Bw+llaHd4cffXXEedXC8zbhFH+T'\n",
    "\n",
    "#Set the Size of the AWS EC2 Instances\n",
    "instance_size = 'm3.xlarge'\n",
    "\n",
    "#Set the Number of Master Instances\n",
    "master_instances = 1\n",
    "\n",
    "#Set the Number of Slave Instances\n",
    "slave_instances = 2\n",
    "\n",
    "#Dataset Provided By Your Instructor\n",
    "dataset_location = 'https://s3-us-west-2.amazonaws.com/dataset-store/amazon_reviews/reviews.json'\n",
    "dataset_file_name = 'reviews.json'\n",
    "\n",
    "#Folder Name for Notebooks Transferring to AWS\n",
    "# Use this for a single file\n",
    "load_notebook_location = 'notebook_name'\n",
    "####################################################################################################################\n",
    "\n",
    "\n",
    "#Import AWS Tools\n",
    "import boto3\n",
    "\n",
    "#Establish The EMR Session\n",
    "emr = boto3.client(\n",
    "   'emr',\n",
    "    region_name=region, \n",
    "    aws_access_key_id = access_id, \n",
    "    aws_secret_access_key = access_key\n",
    ")\n",
    "\n",
    "#Establish The EC2 Session\n",
    "ec2 = boto3.client(\n",
    "    'ec2',\n",
    "    region_name=region, \n",
    "    aws_access_key_id = access_id, \n",
    "    aws_secret_access_key = access_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\") # add current folder for search path to find fabric\n",
    "\n",
    "#Import System Tools\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import getpass\n",
    "from subprocess import call\n",
    "import fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<botocore.client.EMR object at 0x7fc1ddf48208>\n",
      "<botocore.client.EC2 object at 0x7fc1ddbc3710>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Set important Variables\n",
    "system_user_name=getpass.getuser()\n",
    "wk_dir=os.getcwd()\n",
    "\n",
    "print(emr)\n",
    "print(ec2)\n",
    "\n",
    "#Price Calculator Development In Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SSH Keypair\n",
    "This will create a temporary keypair for you to access your cluster and save it to your current working directory. \n",
    "\n",
    "This is automatic so please run this cell as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyName         : EMR-15112021203058-lcmhng\n",
      "Key Fingerprint : 1f:93:a6:fd:f0:0d:2d:1a:56:f5:c5:b0:7d:f5:c0:72:86:90:23:82\n"
     ]
    }
   ],
   "source": [
    "# Create SSH Keypair File For This EMR Cluster\n",
    "\n",
    "emr_pem_file=time.strftime(\"EMR-%d%m%Y%H%M%S-\"+system_user_name)\n",
    "emr_key=ec2.create_key_pair(KeyName=emr_pem_file)\n",
    "\n",
    "#Don't do this unless you have a good reason\n",
    "#print(emr_key['KeyMaterial'])\n",
    "\n",
    "os.system(\"echo \\\"\"+emr_key['KeyMaterial']+\"\\\" > \"+emr_pem_file+\".pem\")\n",
    "os.chmod(wk_dir+\"/\"+emr_pem_file+\".pem\",0o400)\n",
    "\n",
    "print(\"KeyName         : \"+emr_key['KeyName']+\"\\nKey Fingerprint : \"+emr_key['KeyFingerprint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch EMR Cluster\n",
    "This step will launch your Hadoop cluster. From this point on you will be charged money for every hour that this cluster is running. Please proceed with caution.\n",
    "\n",
    "All arguments for the following cell have been set in the first cell. Please run the following cell as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name : EMR Jupyter NB-lcmhng\n",
      "Cluster ID   : j-107B2VBAJV0UP\n"
     ]
    }
   ],
   "source": [
    "# Launch an EMR cluster\n",
    "\n",
    "response = emr.run_job_flow(\n",
    "   Name='EMR Jupyter NB-'+system_user_name,\n",
    "   LogUri='s3n://logs-'+system_user_name+'/elasticmapreduce/',\n",
    "   ReleaseLabel='emr-5.28.0',\n",
    "   Instances={\n",
    "       \n",
    "       'InstanceGroups': [\n",
    "           {\n",
    "               'Name':'Master - 1',\n",
    "               'InstanceRole':'MASTER',\n",
    "               'InstanceType': instance_size,\n",
    "               'InstanceCount': master_instances\n",
    "           },\n",
    "           {\n",
    "               'Name':'Core - 2',\n",
    "               'InstanceRole':'CORE',\n",
    "               'InstanceType': instance_size,\n",
    "               'InstanceCount': slave_instances\n",
    "           }\n",
    "       ],\n",
    "       'KeepJobFlowAliveWhenNoSteps': True,\n",
    "       'TerminationProtected':True,\n",
    "       'Ec2KeyName': emr_pem_file,\n",
    "       'Placement': {\n",
    "           'AvailabilityZone': 'us-west-2c'\n",
    "       }\n",
    "   },\n",
    "\n",
    "\n",
    "#Insert Steps Here if Applicable \n",
    "\n",
    "#Insert Bootstrapping Actions Here if Applicable\n",
    "\n",
    "   \n",
    "   AutoScalingRole=\"EMR_AutoScaling_DefaultRole\",\n",
    "   Applications=[\n",
    "       {\n",
    "           'Name': 'Hadoop'\n",
    "       },\n",
    "       {\n",
    "           'Name': 'Hive'\n",
    "       },\n",
    "       {\n",
    "           'Name': 'Spark'\n",
    "       },\n",
    "       {\n",
    "           'Name': 'Pig'\n",
    "       }\n",
    "   ],\n",
    "   Configurations=[\n",
    "       {\n",
    "           'Classification': 'spark',\n",
    "           'Configurations': [],\n",
    "           'Properties': {\n",
    "               'maximizeResourceAllocation':'true'\n",
    "           }\n",
    "       },\n",
    "   ],\n",
    "   VisibleToAllUsers=False,\n",
    "   EbsRootVolumeSize=10,\n",
    "   JobFlowRole='EMR_EC2_DefaultRole',\n",
    "   ServiceRole='EMR_DefaultRole',\n",
    "   #ScaleDownBehavior='TERMINATE_AT_INSTANCE_HOUR', #For reliese 5.0.0+\n",
    "    \n",
    ")#End of Cluster Launch Command\n",
    "\n",
    "#Define Cluster ID\n",
    "cluster_id = response['JobFlowId']\n",
    "#Get Cluster Info\n",
    "response = emr.describe_cluster(\n",
    "    ClusterId=cluster_id  \n",
    ")\n",
    "print (\"Cluster Name : \"+response['Cluster']['Name']+\"\\nCluster ID   : \"+response['Cluster']['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Please Wait***\n",
      "\n",
      "STARTING...................Cluster DNS Active\n",
      "\n",
      "Proceeding with Firewall Rules...\n"
     ]
    }
   ],
   "source": [
    "#Wait for Bootstrap and Print Cluster Details\n",
    "print (\"\\n***Please Wait***\\n\\n\"+response['Cluster']['Status']['State']+\".\",end=\"\")\n",
    "while True:\n",
    "    response = emr.describe_cluster(\n",
    "        ClusterId=cluster_id  \n",
    "    )\n",
    "    try:\n",
    "        response['Cluster']['MasterPublicDnsName'].find(\"ec2\")\n",
    "        print('...Cluster DNS Active',end=\"\")\n",
    "        break\n",
    "    except:    \n",
    "        time.sleep(5)\n",
    "        print(\".\", end=\"\")\n",
    "        pass\n",
    "\n",
    "print(\"\\n\\nProceeding with Firewall Rules...\")\n",
    "\n",
    "#Get Cluster Security Group Info\n",
    "master_security_group = response['Cluster']['Ec2InstanceAttributes']['EmrManagedMasterSecurityGroup']\n",
    "slave_security_group = response['Cluster']['Ec2InstanceAttributes']['EmrManagedSlaveSecurityGroup']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSH already added\n"
     ]
    }
   ],
   "source": [
    "#Create Firewall Exceptions\n",
    "try:\n",
    "    sec_rule=\"SSH\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 22,\n",
    "             'ToPort': 22,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganglia already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"Ganglia\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 80,\n",
    "             'ToPort': 80,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YARN already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"YARN\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 8088,\n",
    "             'ToPort': 8088,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDFS NameNode already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"HDFS NameNode\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 50070,\n",
    "             'ToPort': 50070,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark History Server already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"Spark History Server\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 18080,\n",
    "             'ToPort': 18080,\n",
    "             'IpRanges': [{'CidrIp': '12.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hue already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"Hue\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 8888,\n",
    "             'ToPort': 8888,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBase already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"HBase\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 16010,\n",
    "             'ToPort': 16010,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter Notebook already added\n",
      "JupyterHub already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"Jupyter Notebook\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 9090,\n",
    "             'ToPort': 9090,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "\n",
    "    \n",
    "    \n",
    "try:\n",
    "    sec_rule=\"JupyterHub\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=master_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 9443,\n",
    "             'ToPort': 9443,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slave SSH already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"Slave SSH\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=slave_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 22,\n",
    "             'ToPort': 22,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slave YARN NodeManager already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"Slave YARN NodeManager\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=slave_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 8042,\n",
    "             'ToPort': 8042,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slave HDFS DataNode already added\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sec_rule=\"Slave HDFS DataNode\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=slave_security_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 50075,\n",
    "             'ToPort': 50075,\n",
    "             'IpRanges': [{'CidrIp': '128.206.0.0/16'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finishing Startup.\n",
      "This will take a few minutes...\n",
      "\n",
      "***Please Wait***\n",
      "\n",
      "Starting...................................................Done"
     ]
    }
   ],
   "source": [
    "print (\"\\n\\nFinishing Startup.\\nThis will take a few minutes...\\n\\n***Please Wait***\\n\\nStarting.\",end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while str(response['Cluster']['Status']['State']) == 'STARTING':\n",
    "        time.sleep(5)\n",
    "        print(\".\", end=\"\")\n",
    "        response = emr.describe_cluster(\n",
    "            ClusterId=cluster_id  \n",
    "        )\n",
    "print('...Done',end=\"\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running Bootstrap Actions.\n",
      "This will take a few minutes...\n",
      "\n",
      "***Please Wait***\n",
      "\n",
      "Bootstrapping....Done\n",
      "\n",
      "Cluster Status: WAITING\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\\nRunning Bootstrap Actions.\\nThis will take a few minutes...\\n\\n***Please Wait***\\n\\nBootstrapping.\",end=\"\")\n",
    "\n",
    "while str(response['Cluster']['Status']['State']) == 'BOOTSTRAPPING':\n",
    "        time.sleep(5)\n",
    "        print(\".\", end=\"\")\n",
    "        response = emr.describe_cluster(\n",
    "            ClusterId=cluster_id  \n",
    "        )\n",
    "print('...Done',end=\"\")  \n",
    "print('\\n\\nCluster Status: '+response['Cluster']['Status']['State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SSHConfig in module paramiko.config:\n",
      "\n",
      "class SSHConfig(builtins.object)\n",
      " |  Representation of config information as stored in the format used by\n",
      " |  OpenSSH. Queries can be made via `lookup`. The format is described in\n",
      " |  OpenSSH's ``ssh_config`` man page. This class is provided primarily as a\n",
      " |  convenience to posix users (since the OpenSSH format is a de-facto\n",
      " |  standard on posix) but should work fine on Windows too.\n",
      " |  \n",
      " |  .. versionadded:: 1.6\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Create a new OpenSSH config object.\n",
      " |  \n",
      " |  get_hostnames(self)\n",
      " |      Return the set of literal hostnames defined in the SSH config (both\n",
      " |      explicit hostnames and wildcard entries).\n",
      " |  \n",
      " |  lookup(self, hostname)\n",
      " |      Return a dict (`SSHConfigDict`) of config options for a given hostname.\n",
      " |      \n",
      " |      The host-matching rules of OpenSSH's ``ssh_config`` man page are used:\n",
      " |      For each parameter, the first obtained value will be used.  The\n",
      " |      configuration files contain sections separated by ``Host``\n",
      " |      specifications, and that section is only applied for hosts that match\n",
      " |      one of the patterns given in the specification.\n",
      " |      \n",
      " |      Since the first obtained value for each parameter is used, more host-\n",
      " |      specific declarations should be given near the beginning of the file,\n",
      " |      and general defaults at the end.\n",
      " |      \n",
      " |      The keys in the returned dict are all normalized to lowercase (look for\n",
      " |      ``\"port\"``, not ``\"Port\"``. The values are processed according to the\n",
      " |      rules for substitution variable expansion in ``ssh_config``.\n",
      " |      \n",
      " |      Finally, please see the docs for `SSHConfigDict` for deeper info on\n",
      " |      features such as optional type conversion methods, e.g.::\n",
      " |      \n",
      " |          conf = my_config.lookup('myhost')\n",
      " |          assert conf['passwordauthentication'] == 'yes'\n",
      " |          assert conf.as_bool('passwordauthentication') is True\n",
      " |      \n",
      " |      :param str hostname: the hostname to lookup\n",
      " |      \n",
      " |      .. versionchanged:: 2.5\n",
      " |          Returns `SSHConfigDict` objects instead of dict literals.\n",
      " |  \n",
      " |  parse(self, file_obj)\n",
      " |      Read an OpenSSH config from the given file object.\n",
      " |      \n",
      " |      :param file_obj: a file-like object to read the config file from\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  SETTINGS_REGEX = re.compile('(\\\\w+)(?:\\\\s*=\\\\s*|\\\\s+)(.+)')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import paramiko\n",
    "help(paramiko.config.SSHConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2-18-237-205-140.us-west-2.compute.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "#Refresh Cluster Description\n",
    "response = emr.describe_cluster(\n",
    "    ClusterId=cluster_id  \n",
    ")\n",
    "\n",
    "host_string = response['Cluster']['MasterPublicDnsName']\n",
    "print(host_string)\n",
    "\n",
    "#Bootstrap Cluster with Fabric\n",
    "from fabric import tasks\n",
    "from fabric import Connection\n",
    "\n",
    "# env.host_string = response['Cluster']['MasterPublicDnsName']\n",
    "# env.user = 'hadoop'\n",
    "# env.key_filename = wk_dir+\"/\"+emr_pem_file+\".pem\"\n",
    "# env.warn_only\n",
    "# env.FABRIC_RUN_HIDE=\"true\"\n",
    "\n",
    "\n",
    "c = Connection(\n",
    "    host=host_string,\n",
    "    user=\"hadoop\",\n",
    "    connect_kwargs={\n",
    "        \"key_filename\": wk_dir+\"/\"+emr_pem_file+\".pem\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_jupyter(fab_conn):\n",
    "    fab_conn.run('sudo python3 -m pip install -U pip')\n",
    "    fab_conn.run('sudo python3 -m pip install -U setuptools')\n",
    "    fab_conn.run('sudo python3 -m pip install jupyter')\n",
    "    fab_conn.run('sudo python3 -m pip install toree')\n",
    "    fab_conn.run('export SPARK_HOME=/usr/lib/spark;export PYTHONPATH=$PYTHONPATH:$SPARK_HOME/python:$SPARK_HOME/python/lib')\n",
    "    fab_conn.run('sudo -u root /usr/local/bin/jupyter toree install --replace --spark_home=/usr/lib/spark --spark_opts=\"--master=local[*]\" --interpreters=Scala,PySpark,SparkR,SQL')\n",
    "    fab_conn.run('mkdir -p /home/hadoop/.jupyter/')\n",
    "    fab_conn.run('curl -o /home/hadoop/.jupyter/jupyter_notebook_config.py https://s3-us-west-2.amazonaws.com/dsa-mizzou/scripts/jupyter_notebook_config.py')\n",
    "    fab_conn.run('sudo -u root yum -y install tmux')\n",
    "    fab_conn.run('tmux new-session -d \"jupyter notebook --no-browser --config /home/hadoop/.jupyter/jupyter_notebook_config.py\"')\n",
    "\n",
    "def load_dataset(fab_conn):\n",
    "    fab_conn.run('/usr/bin/hadoop fs -mkdir Datasets')\n",
    "    fab_conn.run('curl '+dataset_location+' | hadoop fs -appendToFile - Datasets/'+dataset_file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing Jupyter...\n",
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/6d/6463d49a933f547439d6b5b98b46af8742cc03ae83543e4d7688c2420f8b/pip-21.3.1-py3-none-any.whl (1.7MB)\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 9.0.3\n",
      "    Uninstalling pip-9.0.3:\n",
      "      Successfully uninstalled pip-9.0.3\n",
      "Successfully installed pip-21.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.6/site-packages\n",
      "sysconfig: /usr/lib/python3.6/site-packages\n",
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/include/python3.6/UNKNOWN\n",
      "sysconfig: /usr/include/python3.6m/UNKNOWN\n",
      "WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\n",
      "WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /usr/lib/python3.6/dist-packages (36.2.7)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-59.1.1-py3-none-any.whl (951 kB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 36.2.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    WARNING: Value for bin_prefix does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "    distutils: /usr/bin\n",
      "    sysconfig: /usr/local/bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling setuptools-36.2.7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    WARNING: Additional context:\n",
      "    user = False\n",
      "    home = None\n",
      "    root = None\n",
      "    prefix = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled setuptools-36.2.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/setuptools\n",
      "  sysconfig: /usr/include/python3.6m/setuptools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed setuptools-59.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.6/site-packages\n",
      "sysconfig: /usr/lib/python3.6/site-packages\n",
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/include/python3.6/UNKNOWN\n",
      "sysconfig: /usr/include/python3.6m/UNKNOWN\n",
      "WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\n",
      "WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting nbconvert\n",
      "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.4.0-py3-none-any.whl (22 kB)\n",
      "Collecting notebook\n",
      "  Downloading notebook-6.4.5-py3-none-any.whl (9.9 MB)\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.2.0-py3-none-any.whl (120 kB)\n",
      "Collecting traitlets>=4.1.0\n",
      "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting jupyter-client\n",
      "  Downloading jupyter_client-7.0.6-py3-none-any.whl (125 kB)\n",
      "Collecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tornado>=4.2\n",
      "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
      "Collecting ipython>=5.0.0\n",
      "  Downloading ipython-7.16.1-py3-none-any.whl (785 kB)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Downloading nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.10.0-py3-none-any.whl (1.0 MB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.22-py3-none-any.whl (374 kB)\n",
      "Collecting testpath\n",
      "  Downloading testpath-0.5.0-py3-none-any.whl (84 kB)\n",
      "Collecting jinja2>=2.4\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.8-py3-none-any.whl (70 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jupyter-core\n",
      "  Downloading jupyter_core-4.9.1-py3-none-any.whl (86 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting Send2Trash>=1.5.0\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.12.1-py3-none-any.whl (15 kB)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.12.0-py2.py3-none-any.whl (57 kB)\n",
      "Collecting pyzmq>=17\n",
      "  Downloading pyzmq-22.3.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.1.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl (96 kB)\n",
      "Collecting qtpy\n",
      "  Downloading QtPy-1.11.2-py2.py3-none-any.whl (58 kB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-5.1.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pexpect\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter) (59.1.1)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting nest-asyncio>=1.5\n",
      "  Downloading nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\n",
      "Collecting async-generator\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting ptyprocess\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel->jupyter) (1.12.0)\n",
      "Collecting cffi>=1.0.0\n",
      "  Downloading cffi-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (405 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-21.2-py3-none-any.whl (40 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting parso<0.9.0,>=0.8.0\n",
      "  Downloading parso-0.8.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting pyparsing<3,>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-4.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: zipp, typing-extensions, ipython-genutils, decorator, traitlets, pyrsistent, importlib-metadata, attrs, wcwidth, tornado, pyzmq, python-dateutil, pyparsing, ptyprocess, parso, nest-asyncio, jupyter-core, jsonschema, entrypoints, webencodings, pygments, pycparser, prompt-toolkit, pickleshare, pexpect, packaging, nbformat, MarkupSafe, jupyter-client, jedi, backcall, async-generator, testpath, pandocfilters, nbclient, mistune, jupyterlab-pygments, jinja2, ipython, defusedxml, cffi, bleach, terminado, Send2Trash, prometheus-client, nbconvert, ipykernel, argon2-cffi, notebook, widgetsnbextension, qtpy, jupyterlab-widgets, qtconsole, jupyter-console, ipywidgets, jupyter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/zipp\n",
      "  sysconfig: /usr/include/python3.6m/zipp\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/typing-extensions\n",
      "  sysconfig: /usr/include/python3.6m/typing-extensions\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/ipython-genutils\n",
      "  sysconfig: /usr/include/python3.6m/ipython-genutils\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/decorator\n",
      "  sysconfig: /usr/include/python3.6m/decorator\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/traitlets\n",
      "  sysconfig: /usr/include/python3.6m/traitlets\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/pyrsistent\n",
      "  sysconfig: /usr/include/python3.6m/pyrsistent\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/importlib-metadata\n",
      "  sysconfig: /usr/include/python3.6m/importlib-metadata\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/attrs\n",
      "  sysconfig: /usr/include/python3.6m/attrs\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/wcwidth\n",
      "  sysconfig: /usr/include/python3.6m/wcwidth\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/tornado\n",
      "  sysconfig: /usr/include/python3.6m/tornado\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/pyzmq\n",
      "  sysconfig: /usr/include/python3.6m/pyzmq\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/python-dateutil\n",
      "  sysconfig: /usr/include/python3.6m/python-dateutil\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/pyparsing\n",
      "  sysconfig: /usr/include/python3.6m/pyparsing\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/ptyprocess\n",
      "  sysconfig: /usr/include/python3.6m/ptyprocess\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/parso\n",
      "  sysconfig: /usr/include/python3.6m/parso\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/nest-asyncio\n",
      "  sysconfig: /usr/include/python3.6m/nest-asyncio\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/jupyter-core\n",
      "  sysconfig: /usr/include/python3.6m/jupyter-core\n",
      "  WARNING: The scripts jupyter, jupyter-migrate and jupyter-troubleshoot are installed in '/usr/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/jsonschema\n",
      "  sysconfig: /usr/include/python3.6m/jsonschema\n",
      "  WARNING: The script jsonschema is installed in '/usr/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/entrypoints\n",
      "  sysconfig: /usr/include/python3.6m/entrypoints\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/webencodings\n",
      "  sysconfig: /usr/include/python3.6m/webencodings\n",
      "  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.6/pygments\n",
      "  sysconfig: /usr/include/python3.6m/pygments\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nInstalling Jupyter...')        \n",
    "install_jupyter(c)\n",
    "print('\\nDone\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Dataset...')\n",
    "load_dataset(c)\n",
    "print('\\nDone\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a single file/directory\n",
    "#os.system(\"scp -o StrictHostKeyChecking=no -r -i \"+wk_dir+\"/\"+emr_pem_file+\".pem \"+wk_dir+\"/\"+load_notebook_location+\"/.\"+\" hadoop@\"+response['Cluster']['MasterPublicDnsName']+\":/home/hadoop/\" )\n",
    "\n",
    "#Upload Notebook Directory\n",
    "os.system(\"scp -o StrictHostKeyChecking=no -r -i \"+wk_dir+\"/\"+emr_pem_file+\".pem \"+wk_dir+\"/\"+\" hadoop@\"+response['Cluster']['MasterPublicDnsName']+\":/home/hadoop/\" )\n",
    "\n",
    "print('Please Proceed to the Next Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access your EMR Cluster's Interfaces\n",
    "\n",
    "#### For Web Interfaces Run the Following Cell\n",
    "\n",
    "\n",
    "We are interested in running the Jupyter notebook on cluster. So click on the first link for launching Jupyterhub on EMR cluster. Here you can find the notebooks you uploaded.  **Note**:  You may not be able to access your Jupyter Notebooks due to recent firewall rule changes in AWS.  Instead, just try some of the other URLs to see that you can access some of the services for your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web Addresses to EMR\n",
    "print(\"Jupyter Notebooks\\nhttp://\"+response['Cluster']['MasterPublicDnsName']+\":9090/\\n\")\n",
    "print(\"YARN ResourceManager\\nhttp://\"+response['Cluster']['MasterPublicDnsName']+\":8088/\\n\")\n",
    "print(\"Hadoop HDFS NameNode\\nhttp://\"+response['Cluster']['MasterPublicDnsName']+\":50070/\\n\")\n",
    "print(\"Spark HistoryServer\\nhttp://\"+response['Cluster']['MasterPublicDnsName']+\":18080/\\n\")\n",
    "print(\"Hue\\nhttp://\"+response['Cluster']['MasterPublicDnsName']+\":8888/\\n\")\n",
    "print(\"Ganglia\\nhttp://\"+response['Cluster']['MasterPublicDnsName']+\"/ganglia/\\n\")\n",
    "print(\"HBase UI\\nhttp://\"+response['Cluster']['MasterPublicDnsName']+\":16010/\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not doing anything in the terminal. So you dont have to worry about doing SSH into the master. Ignore below cell.\n",
    "\n",
    "\n",
    "#### For SSH, Run the Following Cell and See Instructions Below\n",
    " 1. Run the Cell below\n",
    " 1. Highlight the ssh line and press Ctrl+C to copy it to your local clipboard\n",
    " 1. Click the link below to open a termainal\n",
    " 1. Paste the SSH link in (Ctrl + V) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSH to EMR\n",
    "print(\"ssh -i \"+wk_dir+\"/\"+emr_pem_file+\".pem\"+\" hadoop@\"+response['Cluster']['MasterPublicDnsName'])\n",
    "print(\"https://europa.dsa.missouri.edu/user/\"+system_user_name+\"/terminals/1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your pasted command and output should look similar to:\n",
    "\n",
    "```\n",
    "$ ssh -i /dsa/home/scottgs/jupyter/CloudComputingDataAnalytics/module5/labs/EMR-12022019234354-scottgs.pem hadoop@ec2-34-216-17-40.us-west-2.compute.amazonaws.com\n",
    "Last login: Wed Feb 13 07:39:35 2019\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-ami/2017.03-release-notes/\n",
    "13 package(s) needed for security, out of 243 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "Amazon Linux version 2018.03 is available.\n",
    "\n",
    "EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR\n",
    "E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R\n",
    "EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R\n",
    "  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R\n",
    "  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R\n",
    "  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R\n",
    "  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR\n",
    "  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R\n",
    "  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R\n",
    "  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R\n",
    "EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R\n",
    "E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R\n",
    "EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR\n",
    "\n",
    "[hadoop@ip-172-31-11-173 ~]$\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Your Results\n",
    "\n",
    "Run below cell to get back the notebooks you have run in EMR cluster. A new directory called 'Results' is created in your current directory with all the notebooks you have on EMR cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download all contents of hadoop user to local working directory\n",
    "os.system(\"rm -rf \"+wk_dir+\"/results\")\n",
    "os.system(\"mkdir \"+wk_dir+\"/results\")\n",
    "#print(\"scp -o StrictHostKeyChecking=no -r -i \"+wk_dir+\"/\"+emr_pem_file+\".pem hadoop@\"+response['Cluster']['MasterPublicDnsName']+\":/home/hadoop/labs/* \"+wk_dir+\"/results/\")\n",
    "os.system(\"scp -o StrictHostKeyChecking=no -r -i \"+wk_dir+\"/\"+emr_pem_file+\".pem hadoop@\"+response['Cluster']['MasterPublicDnsName']+\":/home/hadoop/labs/* \"+wk_dir+\"/results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminate Your Cluster\n",
    "Once your work is complete please run the following cells to terminate your cluster and delete your cluster's keypair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Termination Protection\n",
    "emr.set_termination_protection(\n",
    "    JobFlowIds=[\n",
    "        cluster_id,\n",
    "    ],\n",
    "    TerminationProtected=False\n",
    ")\n",
    "# Terminate Cluster\n",
    "response = emr.terminate_job_flows(\n",
    "    JobFlowIds=[\n",
    "       cluster_id ,\n",
    "    ]\n",
    ")\n",
    "print('\\nAWS Metadata: ')\n",
    "print('http Status Code : '+str(response['ResponseMetadata']['HTTPStatusCode']))\n",
    "print('Request ID       : '+response['ResponseMetadata']['RequestId'])\n",
    "print('Retries          : '+str(response['ResponseMetadata']['RetryAttempts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete SSH Keypair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete SSH Keypair\n",
    "\n",
    "try:\n",
    "    os.remove(emr_pem_file+'.pem')\n",
    "    print('Local Key Deleted')\n",
    "except:\n",
    "    print('Local Key Not Found')\n",
    "    \n",
    "response = ec2.delete_key_pair(KeyName=emr_pem_file)\n",
    "print('\\nAWS Metadata: ')\n",
    "print('http Status Code : '+str(response['ResponseMetadata']['HTTPStatusCode']))\n",
    "print('Request ID       : '+response['ResponseMetadata']['RequestId'])\n",
    "print('Retries          : '+str(response['ResponseMetadata']['RetryAttempts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
