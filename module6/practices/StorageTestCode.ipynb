{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Practice to set up VM tools and Python write some code\n",
    "\n",
    "**NOTE**: For this practice, you will work in a Preemptible micro VM.  \n",
    "\n",
    "**NOTE**: When you are done, use the \"Stop\" function from the console on the VM instead of the \"Delete\" function.\n",
    " * Then you can restart the VM for the exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Python Setup Tools\n",
    "\n",
    "### Check type of Linux at VM command line (from SSH Shell)\n",
    "  * `uname -a`\n",
    "  \n",
    "#### Output should look similar to:\n",
    "```\n",
    "Linux instance-1 4.9.0-8-amd64 #1 SMP Debian 4.9.130-2 (2018-10-27) x86_64 GNU/Linux\n",
    "```\n",
    " * Note, we see _Debian_\n",
    "\n",
    "\n",
    "### Following PIP install instructions for Debian\n",
    "\n",
    "https://packaging.python.org/guides/installing-using-linux-tools/#installing-pip-setuptools-wheel-with-linux-package-managers\n",
    "\n",
    "\n",
    "### Installing Google Cloud Python Interface\n",
    "  * `pip3 install google-cloud`\n",
    "  \n",
    "### Install git\n",
    "  * `sudo apt-get install git`\n",
    "\n",
    "### Clone down the GCP Python Docs Samples\n",
    " `git clone https://github.com/GoogleCloudPlatform/python-docs-samples.git`\n",
    "  \n",
    "#### Output may look like:\n",
    "```\n",
    "Collecting google-cloud\n",
    "  Downloading https://files.pythonhosted.org/packages/ba/b1/7c54d1950e7808df06642274e677dbcedba57f75307adf2e5ad8d39e5e0e/google_cloud-0.34.0-py2.py3-none-any.whl\n",
    "Installing collected packages: google-cloud\n",
    "Successfully installed google-cloud-0.34.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Set up Virtual Environment\n",
    " * See: https://cloud.google.com/python/setup\n",
    "   * Section: **Installing and using virtualenv**\n",
    "   * Remember we are using `pip3` not `pip` because of previous steps.\n",
    "   \n",
    "#### Deviation from google instructions: Launch the VirtualEnvironment\n",
    " * `python3 -m virtualenv env`\n",
    "\n",
    "\n",
    "You should see the virtual environment prompt change:\n",
    "```\n",
    "instance-1:~$ source env/bin/activate\n",
    "(env) grantscott_phd@instance-1:~$ \n",
    "```\n",
    "\n",
    "#### In your virtual environments, move into the samples for storage/api\n",
    " * `cd python-docs-samples/storage/api/`\n",
    " \n",
    "#### Make sure the requirements are installed\n",
    " * `pip3 install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Programmatic Access to GCP Storage Buckets\n",
    "\n",
    "## Bucket Help From:\n",
    "\n",
    "https://cloud.google.com/storage/docs/object-basics\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/storage/cloud-client\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/storage/api\n",
    "\n",
    "\n",
    "## Review the Readme for the list of relevant example code nuggets.\n",
    "\n",
    "Example: **list_objects.py**\n",
    "```\n",
    "python3 list_objects.py dsa_mini_project_scottgs{\n",
    "  \"name\": \"dsa_mini_project_scottgs\",\n",
    "  \"id\": \"dsa_mini_project_scottgs\",\n",
    "  \"kind\": \"storage#bucket\",\n",
    "  \"selfLink\": \"https://www.googleapis.com/storage/v1/b/dsa_mini_project_scottgs\",\n",
    "  \"metageneration\": \"1\",\n",
    "  \"etag\": \"CAE=\",\n",
    "  \"updated\": \"2017-12-09T17:25:58.610Z\",\n",
    "  \"storageClass\": \"MULTI_REGIONAL\",\n",
    "  \"projectNumber\": \"684237336060\",\n",
    "  \"timeCreated\": \"2017-12-09T17:25:58.610Z\",\n",
    "  \"location\": \"US\"\n",
    "}\n",
    "[\n",
    "  {\n",
    "    \"name\": \"my_file_1\",\n",
    "    \"contentType\": \"text/plain\",\n",
    "    \"size\": \"15\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"my_file_2\",\n",
    "    \"contentType\": \"text/plain\",\n",
    "    \"size\": \"21\"\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up machine-to-machine access\n",
    "\n",
    "The Google Cloud Python interface allows python scripts to interact with the GCP services and resources.\n",
    "\n",
    "https://googleapis.github.io/google-cloud-python/\n",
    "\n",
    "If you desire to interact with the cloud services and resources from a computer such as your laptop or the MU DSA Jupyter environment, you will need to generate the application default login configuration file.\n",
    "\n",
    "https://cloud.google.com/sdk/gcloud/reference/auth/application-default/login\n",
    "\n",
    "**NOTE:** If you are on a GCloud VM, you will see this is not necessary.\n",
    "\n",
    " * `gcloud auth application-default login`\n",
    " \n",
    "#### Output approximately:\n",
    "```\n",
    "You are running on a Google Compute Engine virtual machine.\n",
    "The service credentials associated with this virtual machine\n",
    "will automatically be used by Application Default\n",
    "Credentials, so it is not necessary to use this command.\n",
    "```\n",
    "\n",
    "##### The next cell is an example of what is necessary for non-GCP servers\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Update the next line!  Requires you uploaded the JSON file for Service Account Auth\n",
    "MY_USERID = 'scottgs'\n",
    "# /home/scottgs/.config/gcloud/application_default_credentials.json\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/\" + MY_PAWPRINT + \"/.config/gcloud/application_default_credentials.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### These functions are from the Github demo repo\n",
    "\n",
    "Please give these cells a read through... and as you do, move them to a file in your virtual machine, such as \n",
    "  * `my_gcp_storage_test.py`\n",
    "  \n",
    "Alternatively, see the Notebook python script extraction example at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be766f6a6749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m## Change to your own project name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mPROJECT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mu-dsa'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "## Change to your own project name\n",
    "PROJECT='lcmhng-mu-dsa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    blobs = bucket.list_blobs()\n",
    "\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blobs_with_prefix(bucket_name, prefix, delimiter=None):\n",
    "    \"\"\"Lists all the blobs in the bucket that begin with the prefix.\n",
    "    This can be used to list all blobs in a \"folder\", e.g. \"public/\".\n",
    "    The delimiter argument can be used to restrict the results to only the\n",
    "    \"files\" in the given \"folder\". Without the delimiter, the entire tree under\n",
    "    the prefix is returned. For example, given these blobs:\n",
    "        /a/1.txt\n",
    "        /a/b/2.txt\n",
    "    If you just specify prefix = '/a', you'll get back:\n",
    "        /a/1.txt\n",
    "        /a/b/2.txt\n",
    "    However, if you specify prefix='/a' and delimiter='/', you'll get back:\n",
    "        /a/1.txt\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    blobs = bucket.list_blobs(prefix=prefix, delimiter=delimiter)\n",
    "\n",
    "    print('Blobs:')\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "\n",
    "    if delimiter:\n",
    "        print('Prefixes:')\n",
    "        for prefix in blobs.prefixes:\n",
    "            print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print('File {} uploaded to {}.'.format(\n",
    "        source_file_name,\n",
    "        destination_blob_name))\n",
    "\n",
    "\n",
    "def upload_as_blob(bucket_name, source_data, destination_blob_name, content_type='text/plain'):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    #blob.upload_from_filename(source_file_name)\n",
    "    blob.upload_from_string(source_data, content_type=content_type)\n",
    "    \n",
    "    print('Data uploaded to {}.'.format(destination_blob_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print('Blob {} downloaded to {}.'.format(\n",
    "        source_blob_name,\n",
    "        destination_file_name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_blob(bucket_name, blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    blob.delete()\n",
    "\n",
    "    print('Blob {} deleted.'.format(blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket Name:\n",
    "my_bucket_name = 'dsa_mini_project_lcmhng'\n",
    "\n",
    "list_blobs(my_bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_as_blob(my_bucket_name, \"This is my data\", 'my_file_1')\n",
    "\n",
    "list_blobs(my_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_as_blob(my_bucket_name, \"This is my other data\", 'my_file_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_blobs(my_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_blob(bucket_name, source_blob_name):\n",
    "    \"\"\"Downloads a blob from the bucket and returns content in bytearray\"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    return blobdownload_as_string()\n",
    "\n",
    "\n",
    "read_blob(my_bucket_name,'my_file_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_blob_as_string(bucket_name, source_blob_name):\n",
    "    \"\"\"Downloads a blob from the bucket and returns content in string\"\"\"\n",
    "    storage_client = storage.Client(project=PROJECT)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    return blob.download_as_string().decode(\"utf-8\") \n",
    "\n",
    "\n",
    "myContent_Back = read_blob_as_string(my_bucket_name,'my_file_2')\n",
    "print(myContent_Back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### When you are ready, let's export this\n",
    " 1. Open terminal\n",
    " 2. Change into course, module6, practices folder\n",
    " 3. Convert to a script: `jupyter-nbconvert --to script StorageTestCode.ipynb`\n",
    "```\n",
    "[NbConvertApp] Converting notebook StorageTestCode.ipynb to script\n",
    "[NbConvertApp] Writing 4740 bytes to StorageTestCode.py\n",
    "```\n",
    "\n",
    "#### Move the generated script using `scp` or copy and paste techniques to get it to your VM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
