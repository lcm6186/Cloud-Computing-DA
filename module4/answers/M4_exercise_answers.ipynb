{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Lambda for S3\n",
    "\n",
    "-----\n",
    "\n",
    "This notebook walks you through steps to create thumbnails for each image (.jpg and .png objects) uploaded to a S3 bucket. \n",
    "You will create a Lambda function (CreateThumbnail) that Amazon S3 invokes when objects are created. \n",
    "Then, the Lambda function will read the image object from the source bucket and create a thumbnail image in target bucket. \n",
    "We call it the _sourceresized_ bucket.\n",
    "\n",
    "**Important**\n",
    "There must be two buckets one for source and target. \n",
    "If you use the same bucket as the source and the target, each thumbnail uploaded to the source bucket triggers another object-created event, which then invokes the Lambda function again, creating an unwanted recursion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/s3_flow.PNG\">\n",
    "\n",
    "Taken from AWS website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence of actions performed.\n",
    "\n",
    "- A user uploads an object to the source bucket in Amazon S3 (object-created event).\n",
    "\n",
    "\n",
    "- Amazon S3 detects the object-created event.\n",
    "\n",
    "\n",
    "- Amazon S3 publishes the s3:ObjectCreated:* event to AWS Lambda by invoking the Lambda function and passing event data as a function parameter.\n",
    "\n",
    "\n",
    "- AWS Lambda executes the Lambda function by assuming the execution role that you specified at the time you created the Lambda function.\n",
    "\n",
    "\n",
    "- From the event data it receives, the Lambda function knows the source bucket name and object key name. The Lambda function reads the object and creates a thumbnail using graphics libraries, and saves it to the target bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/module4_exercises_process_flow.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### SET THE FOLLOWING PARAMETERS ###################################################\n",
    "#***********************************************************************************\n",
    "#Set the AWS Region\n",
    "region = 'us-east-1'#***************************************************************\n",
    "\n",
    "#Set the AWS Access ID (Given to you buy the DSA staff)\n",
    "access_id = '<>'  \n",
    "\n",
    "#Set the AWS Access Key (Given to you buy the DSA staff)\n",
    "access_key = '<>' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "import zipfile\n",
    "import datetime\n",
    "import pandas\n",
    "import json\n",
    "import time\n",
    "import getpass\n",
    "from subprocess import call\n",
    "\n",
    "# Set the username from system\n",
    "system_user_name=getpass.getuser()\n",
    "\n",
    "# Set the source S3 bucket name\n",
    "source=system_user_name+\".source\"\n",
    "\n",
    "# Set the target S3 bucket name\n",
    "sourceresized=system_user_name+\".sourceresized\"\n",
    "\n",
    "# Set the lambda name\n",
    "lambda_name=system_user_name+\"_CreateThumbnail\"\n",
    "\n",
    "# ami image code\n",
    "ami_image = 'ami-8c1be5f6'\n",
    "\n",
    "s3 = boto3.resource('s3', \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "iam = boto3.client('iam', \n",
    "                   aws_access_key_id = access_id,\n",
    "                   aws_secret_access_key = access_key)\n",
    "lamb = boto3.client('lambda', region_name=region, \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "Both the source bucket and the Lambda function must be in the same AWS region. In addition, the code used for the Lambda function also assumes that both of the buckets are in the same region. us-east-1 is the default region in this notebook.\n",
    "\n",
    "You should have set up the AWS CLI by now. If you still haven't configured your credentials in AWS CLI, [click here](../../module2/extra_labs/Accessing_AWS_through_CLI.ipynb#Configuring-the-AWS-CLI) for guide to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.create_bucket(Bucket=source)\n",
    "s3.create_bucket(Bucket=sourceresized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Object(source, 'source.jpg').put(Body=open('../images/ML.jpg', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Deployment Package\n",
    "\n",
    "Following cell has the Python functions carried out by lambda and also installs dependencies. The code uploads the resized image to a different bucket with the same image name, as shown below:\n",
    "\n",
    "    source-bucket/image.png -> source-bucketresized/image.png\n",
    "\n",
    "<br>\n",
    "**Note**\n",
    "The from __future__ statement enables you to write code that is compatible with Python 2 or 3. If you are using runtime version 3.6, it is not necessary to include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening a new file with name in lambda_name(which essentially system_user_name+\"_CreateThumbnail\") \n",
    "# for example skaf48_CreateThumbnail in write mode.\n",
    "\n",
    "# Writing that small piece of code into the file which is in the form of sring. This is function that executes \n",
    "# when lambda is executed\n",
    "with open(lambda_name+\".py\", \"w\") as myfile:\n",
    "    myfile.write('''\\\n",
    "from __future__ import print_function\n",
    "import boto3\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "     \n",
    "s3_client = boto3.client('s3')\n",
    "     \n",
    "def resize_image(image_path, resized_path):\n",
    "    with Image.open(image_path) as image:\n",
    "        image.thumbnail(tuple(x / 2 for x in image.size))\n",
    "        image.save(resized_path)\n",
    "\n",
    "def handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        bucket = record['s3']['bucket']['name']\n",
    "        key = record['s3']['object']['key'] \n",
    "        download_path = '/tmp/{}{}'.format(uuid.uuid4(), key)\n",
    "        upload_path = '/tmp/resized-{}'.format(key)\n",
    "        \n",
    "        s3_client.download_file(bucket, key, download_path)\n",
    "        resize_image(download_path, upload_path)\n",
    "        s3_client.upload_file(upload_path, '{}resized'.format(bucket), key)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add your python code to the .zip file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Open a zip file with same name in lambda_name(which essentially system_user_name+\"_CreateThumbnail\") in write mode\n",
    "zf = zipfile.ZipFile(lambda_name+\".zip\", \"w\")\n",
    "\n",
    "# Write the contents of above file we created into this zip folder\n",
    "zf.write(lambda_name+\".py\")\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .zip file should contain Lambda function code and also dependencies. The dependencies must be downloaded and copied into the zip file. To do that launch an EC2 instance install the necessary packages and write them to zip file.\n",
    "\n",
    "### Launch an EC2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EC2 client object\n",
    "ec2 = boto3.client('ec2',region_name=region, \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "\n",
    "# Set the Security group name\n",
    "Sec_group_name= system_user_name+\"module4_Sec_group_rsgt3b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Security Group\n",
    "\n",
    "Create a security group and modify the security rules as we need to SSH into the instance to install software packages on it. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the security group\n",
    "sg = ec2.create_security_group(\n",
    "    Description='security grp for module 4',\n",
    "    GroupName=Sec_group_name\n",
    ")\n",
    "Sec_group=sg[\"GroupId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize the security group to allow MU's TCP traffic and SSH requests. Configure the inbound rules to allow traffic as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify Security Configuration to allow MU's IP addresses\n",
    "\n",
    "#Describe Cluster\n",
    "\n",
    "try:\n",
    "    sec_rule=\"ALL TCP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': 65535,\n",
    "             'IpRanges': [{'CidrIp': '0.0.0.0/0'}]},\n",
    "        ],)\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "#     print(data)\n",
    "\n",
    "try:\n",
    "    sec_rule=\"ALL TCP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': 65535,\n",
    "             'UserIdGroupPairs': [{ 'GroupId': Sec_group }]\n",
    "#              'IpRanges': [{'CidrIp': Sec_group}]},\n",
    "            }],\n",
    "#         SourceSecurityGroup=Sec_group_name\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "\n",
    "try:\n",
    "    sec_rule=\"Custom ICMP Rule - IPv4\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'icmp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': -1,\n",
    "             'IpRanges': [{'CidrIp': '173.31.192.195/32'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "#     print(data)\n",
    "\n",
    "try:\n",
    "    sec_rule=\"ALL UDP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'udp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': 65535,\n",
    "             'UserIdGroupPairs': [{ 'GroupId': Sec_group }]\n",
    "            }],\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "#     print(data)\n",
    "\n",
    "    \n",
    "try:\n",
    "    sec_rule=\"ALL ICMP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'icmp',\n",
    "             'FromPort': -1,\n",
    "             'ToPort': -1,\n",
    "             'UserIdGroupPairs': [{ 'GroupId': Sec_group }]\n",
    "            }],\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    sec_rule=\"ALL ICMP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'icmp',\n",
    "             'FromPort': -1,\n",
    "             'ToPort': -1,\n",
    "             'IpRanges': [{'CidrIp': '0.0.0.0/16'}]\n",
    "            }],\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a keypair\n",
    "\n",
    "Create a keypair for the EC2 instance. We first generate a name to create a key with that name and also store the key in a file. ec2.create_key_pair() will create a keypair. System command echo is used to write the contents of keypair generated to a file created with same name as keypair. \n",
    "\n",
    "You have to modify the file permissions to provide readonly access. If the file is open, system will throw an error. Do chmod(file, 0o400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import os\n",
    "\n",
    "ec2_pem_file=time.strftime(\"EC2-%d%m%Y%H%M%S-\"+system_user_name)\n",
    "ec2_key=ec2.create_key_pair(KeyName=ec2_pem_file)\n",
    "\n",
    "#Don't do this unless you have a good reason\n",
    "#print(emr_key['KeyMaterial'])\n",
    "\n",
    "os.system(\"echo \\\"\"+ec2_key['KeyMaterial']+\"\\\" > \"+ec2_pem_file+\".pem\")\n",
    "os.chmod(ec2_pem_file+\".pem\",0o400)\n",
    "\n",
    "print(\"KeyName         : \"+ec2_key['KeyName']+\"\\nKey Fingerprint : \"+ec2_key['KeyFingerprint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = ec2.run_instances(\n",
    "    ImageId=ami_image,\n",
    "    MinCount=1,\n",
    "    MaxCount=1,\n",
    "    KeyName=ec2_pem_file,\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            'ResourceType': 'instance',\n",
    "            'Tags': [\n",
    "                        {   'Key': 'Name',\n",
    "                            'Value': 'Docker_Jupyter'\n",
    "                        }\n",
    "                    ]\n",
    "        }\n",
    "    ],\n",
    "    InstanceType=\"t2.micro\",\n",
    "    SecurityGroupIds=[\n",
    "        Sec_group\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the instance id of newly created EC2 instance.\n",
    "new_instance_id = instances[\"Instances\"][0][\"InstanceId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of Instance\n",
    "\n",
    "Use the poll function to make instance is completely set up and is ready for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_until_completed(client, ins_id):\n",
    "    delay = 2\n",
    "    while True:\n",
    "        instance = client.describe_instances(InstanceIds=[ins_id,])\n",
    "        status = instance[\"Reservations\"][0][\"Instances\"][0][\"State\"][\"Name\"]\n",
    "#         message = cluster.get('Message', '')\n",
    "        now = str(datetime.datetime.now().time())\n",
    "    \n",
    "        print(\"instance %s is %s at %s\" % (ins_id, status, now))\n",
    "        if status in ['running','terminated']:\n",
    "            break\n",
    "\n",
    "        # exponential backoff with jitter\n",
    "        delay *= random.uniform(1.1, 2.0)\n",
    "        time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "poll_until_completed(ec2, new_instance_id)  # Can't use it until it's COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the instanceId captured above, use describe_instances() method to get instance details\n",
    "# instance details has public DNS address.\n",
    "\n",
    "inst_det = ec2.describe_instances(\n",
    "    InstanceIds=[\n",
    "        new_instance_id,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the public DNS of new instance.\n",
    "instance_pub_dns=inst_det[\"Reservations\"][0][\"Instances\"][0][\"PublicDnsName\"]\n",
    "instance_pub_dns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the lambda function code file EC2 instance\n",
    "\n",
    "In my case its \"skaf48_CreateThumbnail.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"scp -o StrictHostKeyChecking=no -i \"+\n",
    "          os.getcwd() +\"/\" + ec2_pem_file + \".pem \"+\n",
    "          lambda_name+\".py \"+\n",
    "          \"ec2-user@\"+instance_pub_dns + \":~/\"+lambda_name+\".py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to EC2 instance via SSH.\n",
    "\n",
    "Run below cell and copy the output. paste it in the terminal. Use the terminal to SSH into the instance and install the software packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ssh -i \"+os.getcwd()+\"/\"+ec2_pem_file+\".pem ec2-user@\"+instance_pub_dns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <span style=\"color:red\">Note:</span>\n",
    "<hr size=\"6\" width=\"100%\" noshade style=\"border-color:#FF0000\" align=\"left\">\n",
    "\n",
    "\n",
    "After you succesfully got into the EC2 instance, **Carefully** run all the commands in following sequence as shown below in the terminal. \n",
    "\n",
    "<br>\n",
    "**Install Python 3.6 and virtualenv using the following steps:**\n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "\n",
    "sudo yum install -y gcc zlib zlib-devel openssl openssl-devel\n",
    "\n",
    "wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tgz\n",
    "\n",
    "tar -xzvf Python-3.6.1.tgz\n",
    "\n",
    "cd Python-3.6.1 && ./configure && make\n",
    "\n",
    "sudo make install\n",
    "\n",
    "sudo /usr/local/bin/pip3 install virtualenv\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "**Choose the virtual environment that was installed via pip3**\n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "/usr/local/bin/virtualenv ~/shrink_venv\n",
    "\n",
    "source ~/shrink_venv/bin/activate\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "**Install libraries in the virtual environment **\n",
    "\n",
    "```bash\n",
    "\n",
    "pip install Pillow\n",
    "\n",
    "pip install boto3\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "** Add the contents of lib and lib64 site-packages to your .zip file.**\n",
    "\n",
    "**Note: ** that the following steps assume you used Python runtime version 3.6. If you used version 2.7 you will need to update accordingly.\n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "cd $VIRTUAL_ENV/lib/python3.6/site-packages\n",
    "\n",
    "zip -r9 ~/pawprint_CreateThumbnail.zip *\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "** Add your python code to the .zip file**\n",
    "\n",
    "```bash\n",
    "\n",
    "cd ~\n",
    "\n",
    "zip -g pawprint_CreateThumbnail.zip pawprint_CreateThumbnail.py\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "**Upload the zip file to S3**. Check to see if the CreateThumbnail.zip file exists by running \"dir\" command. Also run \"aws configure\" so you can access AWS services through Command line. \n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "dir\n",
    "\n",
    "aws configure\n",
    "\n",
    "aws s3api create-bucket --bucket <pawprint>-bucket-module4\n",
    "\n",
    "aws s3 cp pawprint_CreateThumbnail.zip s3://<pawprint>-bucket-module4/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Execution Role (IAM Role)\n",
    "\n",
    "\n",
    "Create an IAM role using the following predefined role type and access permissions policy:\n",
    "\n",
    "- AWS service role of the type AWS Lambda – This role grants AWS Lambda permissions to assume the role. Role Type, would be AWS Lambda in AWS Service Roles. This grants the AWS Lambda service permissions to assume the role.\n",
    "\n",
    "\n",
    "- AWSLambdaExecute access permissions policy that you attach to the role. Attach the default Policy, AWSLambdaBasicExecuteRole.\n",
    "\n",
    "\n",
    "- Enter a Role name and then choose Create role. For Role Name, use a name that is unique within your AWS account (for example, skaf48-lambda-s3-execution-role)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a AWS role for performing lambda \n",
    "\n",
    "def create_role(name, policies=None):\n",
    "    \"\"\" Create a role with an optional inline policy \"\"\"\n",
    "    policydoc = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\"Effect\": \"Allow\", \"Principal\": {\"Service\": [\"lambda.amazonaws.com\"]}, \"Action\": [\"sts:AssumeRole\"]},\n",
    "        ]\n",
    "    }\n",
    "    roles = [r['RoleName'] for r in iam.list_roles()['Roles']]\n",
    "    if name in roles:\n",
    "        print('IAM role %s exists' % (name))\n",
    "        role = iam.get_role(RoleName=name)['Role']\n",
    "    else:\n",
    "        print('Creating IAM role %s' % (name))\n",
    "        role = iam.create_role(RoleName=name, AssumeRolePolicyDocument=json.dumps(policydoc))['Role']\n",
    "\n",
    "    # attach managed policy\n",
    "    if policies is not None:\n",
    "        for p in policies:\n",
    "            iam.attach_role_policy(RoleName=role['RoleName'], PolicyArn=p)\n",
    "    return role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call above function to create the role with predefined role type and access policy\n",
    "role = create_role(system_user_name + '_lambda-s3-execution-role', \n",
    "                   policies=['arn:aws:iam::aws:policy/AWSLambdaExecute'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Lambda Function (Upload the Deployment Package)\n",
    "\n",
    "Create a Lambda function by uploading the deployment package. The piece of code in the zip file we created above is the deployment package. Test the Lambda function by invoking it manually. Instead of creating an event source, we use a sample DynamoDB event data which is a set of json records. \n",
    "\n",
    "----\n",
    "\n",
    "Below function will check if a lambda function with specified name already exists. If yes then it will update the code for existing lambda. Else, it will create a new lambda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function(name, bucket, key, lsize=512, timeout=120, update=False):\n",
    "    \"\"\" Create, or update if exists, lambda function \"\"\"\n",
    "    print(\"role:\",role)\n",
    "\n",
    "    if name in [f['FunctionName'] for f in lamb.list_functions()['Functions']]:\n",
    "        if update:\n",
    "            print('Updating %s lambda function code' % (name))\n",
    "            return lamb.update_function_code(FunctionName=name, S3Bucket=bucket, S3Key=key)\n",
    "        else:\n",
    "            print('Lambda function %s exists' % (name))\n",
    "            for f in lamb.list_functions()['Functions']:\n",
    "                if f['FunctionName'] == name:\n",
    "                    lfunc = f\n",
    "    else:\n",
    "        print('Creating %s lambda function' % (name))\n",
    "        lfunc = lamb.create_function(\n",
    "            FunctionName=name,\n",
    "            Runtime='python3.6',\n",
    "            Role=role['Arn'],\n",
    "            Handler=lambda_name+'.handler',\n",
    "            Description='lambda to monitor S3 events and process the images',\n",
    "            Timeout=timeout,\n",
    "            MemorySize=lsize,\n",
    "            Publish=True,\n",
    "#                 Code={'ZipFile': zipfile.read()},\n",
    "            Code={'S3Bucket':bucket,  # <pawprint>-bucket-module4\n",
    "                  'S3Key':key},\n",
    "        )\n",
    "    lfunc['Role'] = role\n",
    "    return lfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call create_function() to create the lambda. The parameter update=True will ensure the existing lambda is updated with the \n",
    "# supplied code in the zip file.\n",
    "\n",
    "lfunc = create_function(lambda_name,bucket=\"pawprint-bucket-module4\", key=\"pawprint_CreateThumbnail.zip\", update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Lambda Function (Invoke Manually)\n",
    "\n",
    "Invoke the Lambda function manually using sample Amazon S3 event data and test it manually. Following is the Amazon S3 sample event data. \n",
    "\n",
    "**Update the JSON by providing your sourcebucket name. Replace <> with the value in source variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <> with the value in source variable\n",
    "\n",
    "input_data=b\"\"\"{  \n",
    "   \"Records\":[  \n",
    "      {  \n",
    "         \"eventVersion\":\"2.0\",\n",
    "         \"eventSource\":\"aws:s3\",\n",
    "         \"awsRegion\":\"us-east-1\",\n",
    "         \"eventTime\":\"1970-01-01T00:00:00.000Z\",\n",
    "         \"eventName\":\"ObjectCreated:Put\",\n",
    "         \"userIdentity\":{  \n",
    "            \"principalId\":\"AIDAJDPLRKLG7UEXAMPLE\"\n",
    "         },\n",
    "         \"requestParameters\":{  \n",
    "            \"sourceIPAddress\":\"127.0.0.1\"\n",
    "         },\n",
    "         \"responseElements\":{  \n",
    "            \"x-amz-request-id\":\"C3D13FE58DE4C810\",\n",
    "            \"x-amz-id-2\":\"FMyUVURIY8/IgAtTv8xRjskZQpcIZ9KG4V5Wp6S7S/JRWeUWerMUE5JgHvANOjpD\"\n",
    "         },\n",
    "         \"s3\":{  \n",
    "            \"s3SchemaVersion\":\"1.0\",\n",
    "            \"configurationId\":\"testConfigRule\",\n",
    "            \"bucket\":{  \n",
    "               \"name\":\"pawprint.source\",\n",
    "               \"ownerIdentity\":{  \n",
    "                  \"principalId\":\"A3NL1KOZZKExample\"\n",
    "               },\n",
    "               \"arn\":\"arn:aws:s3:::pawprint.source\"  \n",
    "            },\n",
    "            \"object\":{  \n",
    "               \"key\":\"source.jpg\",\n",
    "               \"size\":1024,\n",
    "               \"eTag\":\"d41d8cd98f00b204e9800998ecf8427e\",\n",
    "               \"versionId\":\"096fKKXTRTtl3on89fVO.nfljtsv6qko\"\n",
    "            }\n",
    "         }\n",
    "      }\n",
    "   ]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the lambda manually\n",
    "\n",
    "response = lamb.invoke(\n",
    "    FunctionName=lambda_name,\n",
    "    InvocationType='RequestResponse',\n",
    "    LogType='Tail',\n",
    "    Payload=input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "If the above cell ran succesfully then the test is passed. You should see an image written to sourceresized folder in S3. See below for sample output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/size_comparision.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an Event Source (Configure Amazon S3 to Publish Events)\n",
    "\n",
    "\n",
    "In this step, you add the remaining configuration so that Amazon S3 can publish object-created events to AWS Lambda and invoke the Lambda function. You do the following in this step:\n",
    "\n",
    "- Add permissions to the Lambda function access policy to allow Amazon S3 to invoke the function.\n",
    "\n",
    "\n",
    "- Add notification configuration to your source bucket. In the notification configuration, you provide the following:\n",
    "    \n",
    "    - Event type for which you want Amazon S3 to publish events. For this tutorial, you specify the s3:ObjectCreated:* event type so that Amazon S3 publishes events when objects are created.\n",
    "\n",
    "    - Lambda function to invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lamb.add_permission(\n",
    "    FunctionName=lambda_name,\n",
    "    StatementId=time.strftime(system_user_name+\"%d%m%Y%H%M%S\"), # some-unique-id \n",
    "    Action='lambda:InvokeFunction', \n",
    "    Principal='s3.amazonaws.com',\n",
    "    SourceArn='arn:aws:s3:::rsgt3b.source',   # ARN of the source bucket, Change the value with your pawprint\n",
    "    SourceAccount='714861692883'   # bucket-owner-account-id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the function's access policy by running the AWS CLI get-policy command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lamb.get_policy(\n",
    "    FunctionName=lambda_name\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Notification on the Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add notification configuration on the source bucket to request Amazon S3 to publish object-created events to Lambda. In the configuration, you specify the following:\n",
    "\n",
    "- Event type – For this notebook, its ObjectCreated (All) Amazon S3 event type.\n",
    "\n",
    "\n",
    "- Lambda function – Your Lambda function that you want Amazon S3 to invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lamb.get_function(\n",
    "    FunctionName=lambda_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"Configuration\"][\"FunctionArn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3', \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "\n",
    "response = s3_client.put_bucket_notification_configuration(\n",
    "    Bucket=source,\n",
    "    NotificationConfiguration={\n",
    "        'LambdaFunctionConfigurations': [\n",
    "            {\n",
    "                'Id': 'NewImage',\n",
    "                'LambdaFunctionArn': response[\"Configuration\"][\"FunctionArn\"],\n",
    "                'Events': ['s3:ObjectCreated:*']\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload .jpg or .png objects to the source bucket. Verify that the thumbnail was created in the target bucket using the CreateThumbnail lambda function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Object(source, 'test_image.jpg').put(Body=open('../images/test_image.jpg', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete SSH Keypair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete SSH Keypair\n",
    "\n",
    "try:\n",
    "    os.remove(ec2_pem_file+'.pem')\n",
    "    print('Local Key Deleted')\n",
    "except:\n",
    "    print('Local Key Not Found')\n",
    "    \n",
    "response = ec2.delete_key_pair(KeyName=ec2_pem_file)\n",
    "print('\\nAWS Metadata: ')\n",
    "print('http Status Code : '+str(response['ResponseMetadata']['HTTPStatusCode']))\n",
    "print('Request ID       : '+response['ResponseMetadata']['RequestId'])\n",
    "print('Retries          : '+str(response['ResponseMetadata']['RetryAttempts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminate the EC2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2', region_name=region, \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "\n",
    "ec2.instances.filter(InstanceIds=[new_instance_id,]).terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the security group\n",
    "\n",
    "Run the polling function to make sure instance is terminated. You cant delete the security group while a running instance is using it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "ec2 = boto3.client('ec2', region_name=region, \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "poll_until_completed(ec2, new_instance_id)  # Can't use it until it's COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_delete_response = ec2.delete_security_group(\n",
    "    GroupId=Sec_group,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Save your notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Note: Dont delete the buckets</span>\n",
    "\n",
    "Leave them for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing this cell will delete the source bucket \n",
    "#import boto3\n",
    "#source = 'pawprint.source'\n",
    "#s3 = boto3.resource('s3', \n",
    "#                   aws_access_key_id = access_id, \n",
    "#                   aws_secret_access_key = access_key)\n",
    "#bucket = s3.Bucket(source)\n",
    "\n",
    "#for key in bucket.objects.all():\n",
    "#     key.delete()\n",
    "#bucket.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing this cell will delete the source resized bucket \n",
    "#sourceresized = 'pawprint.sourceresized'\n",
    "#bucket = s3.Bucket(sourceresized)\n",
    "\n",
    "#for key in bucket.objects.all():\n",
    "#    key.delete()\n",
    "#bucket.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing this cell will delete the pawprint-bucket-module4 bucket \n",
    "#bucket-module4 = 'pawprint-bucket-module4'\n",
    "#bucket = s3.Bucket(bucket-module4)\n",
    "\n",
    "#for key in bucket.objects.all():\n",
    "#    key.delete()\n",
    "#bucket.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
