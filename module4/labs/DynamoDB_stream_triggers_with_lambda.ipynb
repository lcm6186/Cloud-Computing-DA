{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure AWS DynamoDB Stream Triggers with AWS Lambda\n",
    "\n",
    "-----\n",
    "Many applications can benefit from the ability to capture changes to items stored in a DynamoDB table, at the point in time when such changes occur. Some of the example use cases are below:\n",
    "\n",
    "- A popular mobile app modifies data in a DynamoDB table, at the rate of thousands of updates per second. Another application captures and stores data about these updates, providing near real time usage metrics for the mobile app.\n",
    "\n",
    "- An application automatically sends notifications to the mobile devices of all friends in a group as soon as one friend uploads a new picture.\n",
    "\n",
    "\n",
    "A DynamoDB stream is an ordered flow of information about changes to items in an Amazon DynamoDB table. When you enable a stream on a table, DynamoDB captures information about every modification to data items in the table. DynamoDB Streams are designed to allow external applications to monitor table updates and react in real-time.\n",
    "\n",
    "An ordered flow of record modifications will become available via a custom API endpoint. Every time you create, update or delete records from the table, DynamoDB will write a new stream record containing the corresponding record data.\n",
    "\n",
    "Whenever an application creates, updates, or deletes items in the table, DynamoDB Streams writes a stream record with the primary key attribute(s) of the items that were modified. A stream record contains information about a data modification to a single item in a DynamoDB table. You can configure the stream so that the stream records capture additional information, such as the \"before\" and \"after\" images of modified items.\n",
    "\n",
    "\n",
    "The stream record information can be configured for each table, choosing between one of the following options:\n",
    "\n",
    "- Keys only - The record will contain only the key attributes of the item.\n",
    "\n",
    "- New image - The record will contain the entire item after it was modified.\n",
    "\n",
    "- Old image - The record will contain the entire item before it was modified.\n",
    "\n",
    "- New and old image - The record will contain both the new and the old items.\n",
    "\n",
    "\n",
    "Please note that stream records are available almost in real-time and always in the correct order. This way, external applications can take arbitrary actions, such as sync cross-region tables, send mobile notifications based on new content, compute real-time usage metrics, etc.\n",
    "\n",
    "In this lab, we will see how to read DynamoDB Streams in a serverless fashion with AWS Lambda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/dynabodb_trigger_flow.PNG\">\n",
    "\n",
    "Taken from AWS website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "import zipfile\n",
    "import datetime\n",
    "import pandas\n",
    "import json\n",
    "import time\n",
    "import getpass\n",
    "from subprocess import call\n",
    "\n",
    "# Set the username from system\n",
    "system_user_name=getpass.getuser()\n",
    "\n",
    "# Set the DynaoDB table name\n",
    "table_name=system_user_name+\"dsa_courses\"\n",
    "\n",
    "# Set the lambda function name\n",
    "lambda_name = system_user_name+\"lambda\"\n",
    "\n",
    "\n",
    "client = boto3.client('dynamodb')\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "iam = boto3.client('iam')\n",
    "lamb = boto3.client('lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We will implement a simple trigger to keep courseid and ismandatory synchronized. Every time a new record is created we will add the computed field (ismandatory). Also, every time a record is updated, we will keep the two fields in sync.\n",
    "\n",
    "The following is a list of possible scenarios to account for:\n",
    "\n",
    "- A new record is created: We will simply initialize isMandatory with the correct value.\n",
    "\n",
    "- A record is modified, but courseId hasn't changed: No operation.\n",
    "\n",
    "- A record is modified, courseId has changed, but isMandatory is still the same: No operation.\n",
    "\n",
    "- A record is modified, courseId has changed and isMandatory needs to be updated: Modify the record.\n",
    "\n",
    "Note that on both (1) and (4) we will trigger a new MODIFY operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS Lambda with Amazon DynamoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stream-based model** – This is a model where AWS Lambda polls the stream 4 times per second and, when it detects new records, invokes your Lambda by passing the update event as parameter.\n",
    "\n",
    "In a stream-based model, you maintain event source mapping in AWS Lambda. The event source mapping describes which stream maps to which Lambda function. AWS Lambda provides an API (CreateEventSourceMapping) for you to create the mapping. You used the AWS Lambda console to create event source mappings in the walkthrough doc - Lambda_First_Tutorial.pdf.\n",
    "\n",
    "----\n",
    "\n",
    "* First, we create a Lambda function and test it by invoking it manually using sample event data.\n",
    "\n",
    "\n",
    "* Second, we create a DynamoDB stream-enabled table and add an event source mapping in AWS Lambda to associate the stream with your Lambda function. AWS Lambda starts polling the stream. Then, test the end-to-end setup. As you create, update, and delete items from the table, Amazon DynamoDB writes records to the stream. AWS Lambda detects the new records as it polls the stream and executes your Lambda function on your behalf.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Opening a new file with name in lambda_name(which essentially system_user_name+\"lambda\") \n",
    "# for example skaf48lambda in write mode.\n",
    "\n",
    "# Writing that small piece of code into the file which is in the form of sring. This is function that executes \n",
    "# when lambda is executed\n",
    "with open(lambda_name+\".py\", \"w\") as myfile:\n",
    "    myfile.write('''\\\n",
    "from __future__ import print_function\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        print(record)\n",
    "    print('Successfully processed %s records.' % str(len(event['Records'])))\n",
    "                 ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Open a zip file with same name in lambda_name(which essentially system_user_name+\"lambda\") in write mode\n",
    "zf = zipfile.ZipFile(lambda_name+\".zip\", \"w\")\n",
    "\n",
    "# Write the contents of above file we created into this zip folder\n",
    "zf.write(lambda_name+\".py\")\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an IAM role\n",
    "\n",
    "AWS service role of the type AWS Lambda – This role grants AWS Lambda permissions to assume the role.\n",
    "AWSLambdaDynamoDBExecutionRole – This is the access permissions policy that you attach to the role.\n",
    "\n",
    "\n",
    "If you want to create am IAM role using AWS web console you will follow below steps. \n",
    "\n",
    "* Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n",
    "\n",
    "\n",
    "* Follow the steps in Creating a Role to Delegate Permissions to an AWS Service in the IAM User Guide to create an IAM role (execution role). As you follow the steps to create a role, note the following:\n",
    "    \n",
    "    - In Role Name, use a name that is unique within your AWS account (for example, lambda-dynamodb-execution-role).\n",
    "\n",
    "    - In Select Role Type, choose AWS Service Roles, and then choose AWS Lambda. This grants the AWS Lambda service permissions to assume the role.\n",
    "\n",
    "    - In Attach Policy, choose AWSLambdaDynamoDBExecutionRole. The permissions in this policy are sufficient for the Lambda function in this tutorial.\n",
    "    \n",
    "<br>\n",
    "Below function does the same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create a AWS role for performing lambda \n",
    "\n",
    "def create_role(name, policies=None):\n",
    "    \"\"\" Create a role with an optional inline policy \"\"\"\n",
    "    policydoc = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\"Effect\": \"Allow\", \"Principal\": {\"Service\": [\"lambda.amazonaws.com\"]}, \"Action\": [\"sts:AssumeRole\"]},\n",
    "        ]\n",
    "    }\n",
    "    roles = [r['RoleName'] for r in iam.list_roles()['Roles']]\n",
    "    if name in roles:\n",
    "        print('IAM role %s exists' % (name))\n",
    "        role = iam.get_role(RoleName=name)['Role']\n",
    "    else:\n",
    "        print('Creating IAM role %s' % (name))\n",
    "        role = iam.create_role(RoleName=name, AssumeRolePolicyDocument=json.dumps(policydoc))['Role']\n",
    "\n",
    "    # attach managed policy\n",
    "    if policies is not None:\n",
    "        for p in policies:\n",
    "            iam.attach_role_policy(RoleName=role['RoleName'], PolicyArn=p)\n",
    "    return role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM role skaf48_lambda-dynamodb-execution-role exists\n"
     ]
    }
   ],
   "source": [
    "# Call above function to create the role with predefined role type and access policy\n",
    "role = create_role(system_user_name + '_lambda-dynamodb-execution-role', \n",
    "                   policies=['arn:aws:iam::aws:policy/service-role/AWSLambdaDynamoDBExecutionRole'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Lambda Function and Test It Manually\n",
    "\n",
    "Create a Lambda function by uploading the deployment package. The piece of code in the zip file we created above is the deployment package. Test the Lambda function by invoking it manually. Instead of creating an event source, we use a sample DynamoDB event data which is a set of json records. \n",
    "\n",
    "----\n",
    "\n",
    "Below function if a lambda function with specified name already exists. If yes then it will update the code for existing lambda. Else, it will create a new lambda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_function(name, zfile, lsize=512, timeout=120, update=False):\n",
    "    \"\"\" Create, or update if exists, lambda function \"\"\"\n",
    "    print(\"role:\",role)\n",
    "    \n",
    "    with open(zfile, 'rb') as zipfile:\n",
    "        if name in [f['FunctionName'] for f in lamb.list_functions()['Functions']]:\n",
    "            if update:\n",
    "                print('Updating %s lambda function code' % (name))\n",
    "                return lamb.update_function_code(FunctionName=name, ZipFile=zipfile.read())\n",
    "            else:\n",
    "                print('Lambda function %s exists' % (name))\n",
    "                for f in lamb.list_functions()['Functions']:\n",
    "                    if f['FunctionName'] == name:\n",
    "                        lfunc = f\n",
    "        else:\n",
    "            print('Creating %s lambda function' % (name))\n",
    "            lfunc = lamb.create_function(\n",
    "                FunctionName=name,\n",
    "                Runtime='python3.6',\n",
    "                Role=role['Arn'],\n",
    "                Handler=lambda_name+'.lambda_handler',\n",
    "                Description='Example lambda function to monitor DynamoDB streams',\n",
    "                Timeout=timeout,\n",
    "                MemorySize=lsize,\n",
    "                Publish=True,\n",
    "                Code={'ZipFile': zipfile.read()},\n",
    "            )\n",
    "        lfunc['Role'] = role\n",
    "        return lfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: {'RoleId': 'AROAISBVGSBM5RBT6VL2S', 'Path': '/', 'CreateDate': datetime.datetime(2017, 11, 8, 19, 42, 25, tzinfo=tzutc()), 'RoleName': 'skaf48_lambda-dynamodb-execution-role', 'AssumeRolePolicyDocument': {'Statement': [{'Action': 'sts:AssumeRole', 'Principal': {'Service': 'lambda.amazonaws.com'}, 'Effect': 'Allow'}], 'Version': '2012-10-17'}, 'Arn': 'arn:aws:iam::714861692883:role/skaf48_lambda-dynamodb-execution-role'}\n",
      "Creating skaf48lambda lambda function\n"
     ]
    }
   ],
   "source": [
    "# Call create_function() to create the lambda. The parameter update=True will ensure the existing lambda is updated with the \n",
    "# supplied code in the zip file.\n",
    "\n",
    "lfunc = create_function(lambda_name, lambda_name+\".zip\", update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample test DynamoDNB record to test the lambda manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = b\"\"\"{\n",
    "   \"Records\":[\n",
    "      {\n",
    "         \"eventID\":\"1\",\n",
    "         \"eventName\":\"INSERT\",\n",
    "         \"eventVersion\":\"1.0\",\n",
    "         \"eventSource\":\"aws:dynamodb\",\n",
    "         \"awsRegion\":\"us-east-1\",\n",
    "         \"dynamodb\":{\n",
    "            \"Keys\":{\n",
    "               \"Id\":{\n",
    "                  \"N\":\"101\"\n",
    "               }\n",
    "            },\n",
    "            \"NewImage\":{\n",
    "               \"Message\":{\n",
    "                  \"S\":\"New item!\"\n",
    "               },\n",
    "               \"Id\":{\n",
    "                  \"N\":\"101\"\n",
    "               }\n",
    "            },\n",
    "            \"SequenceNumber\":\"111\",\n",
    "            \"SizeBytes\":26,\n",
    "            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n",
    "         },\n",
    "         \"eventSourceARN\":\"stream-ARN\"\n",
    "      },\n",
    "      {\n",
    "         \"eventID\":\"2\",\n",
    "         \"eventName\":\"MODIFY\",\n",
    "         \"eventVersion\":\"1.0\",\n",
    "         \"eventSource\":\"aws:dynamodb\",\n",
    "         \"awsRegion\":\"us-east-1\",\n",
    "         \"dynamodb\":{\n",
    "            \"Keys\":{\n",
    "               \"Id\":{\n",
    "                  \"N\":\"101\"\n",
    "               }\n",
    "            },\n",
    "            \"NewImage\":{\n",
    "               \"Message\":{\n",
    "                  \"S\":\"This item has changed\"\n",
    "               },\n",
    "               \"Id\":{\n",
    "                  \"N\":\"101\"\n",
    "               }\n",
    "            },\n",
    "            \"OldImage\":{\n",
    "               \"Message\":{\n",
    "                  \"S\":\"New item!\"\n",
    "               },\n",
    "               \"Id\":{\n",
    "                  \"N\":\"101\"\n",
    "               }\n",
    "            },\n",
    "            \"SequenceNumber\":\"222\",\n",
    "            \"SizeBytes\":59,\n",
    "            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n",
    "         },\n",
    "         \"eventSourceARN\":\"stream-ARN\"\n",
    "      },\n",
    "      {\n",
    "         \"eventID\":\"3\",\n",
    "         \"eventName\":\"REMOVE\",\n",
    "         \"eventVersion\":\"1.0\",\n",
    "         \"eventSource\":\"aws:dynamodb\",\n",
    "         \"awsRegion\":\"us-east-1\",\n",
    "         \"dynamodb\":{\n",
    "            \"Keys\":{\n",
    "               \"Id\":{\n",
    "                  \"N\":\"101\"\n",
    "               }\n",
    "            },\n",
    "            \"OldImage\":{\n",
    "               \"Message\":{\n",
    "                  \"S\":\"This item has changed\"\n",
    "               },\n",
    "               \"Id\":{\n",
    "                  \"N\":\"101\"\n",
    "               }\n",
    "            },\n",
    "            \"SequenceNumber\":\"333\",\n",
    "            \"SizeBytes\":38,\n",
    "            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n",
    "         },\n",
    "         \"eventSourceARN\":\"stream-ARN\"\n",
    "      }\n",
    "   ]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Invoke the lambda manually\n",
    "\n",
    "response = lamb.invoke(\n",
    "    FunctionName=lambda_name,\n",
    "    InvocationType='RequestResponse',\n",
    "    LogType='Tail',\n",
    "    Payload=input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the activity of your Lambda function in the AWS Lambda console.\n",
    "\n",
    "The AWS Lambda console shows a graphical representation of some of the CloudWatch metrics in the Cloudwatch Metrics at a glance section for the function. For each graph you can also click the logs link to view the CloudWatch logs directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to lambda service in AWS web console. The dashboard has graphs for different metrics of the graph. Click on invocation count graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/lambda_graphs.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to custom the time line as highlighted in the picture. Set it to last 30 mins so you can see the number of times lambda is invoked in that time period. Since we invoked the service once in last 30 mins, you see the count 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/invocation count.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on logs in cloudwatch and then on your lambda function to open the logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/cloudwatch_logs.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see logs created for every record in the input. There are 3 events insert, modify and remove. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/logs.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step we will add an Event Source, a DynamoDB. Create a DynamoDB Stream and associate it with above Lambda function.\n",
    "\n",
    "We will do the following below:\n",
    "\n",
    "* Create an Amazon DynamoDB table with a stream enabled.\n",
    "\n",
    "\n",
    "* Create an event source mapping in AWS Lambda. This event source mapping associates the DynamoDB stream with your Lambda function. After you create this event source mapping, AWS Lambda starts polling the stream.\n",
    "\n",
    "\n",
    "* Test the end-to-end experience. As you perform table updates, DynamoDB writes event records to the stream. As AWS Lambda polls the stream, it detects new records in the stream and executes your Lambda function on your behalf by passing events to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "You must create a DynamoDB table in the same region where you created the Lambda function. This notebook assumes the US East (N. Virginia) region. In addition, both the table and the Lambda functions must belong to the same AWS account.\n",
    "\n",
    "In order to receive DynamoDB updates, you need to enable each table's stream. We have enabled table's stream using the parameter StreamSpecification as shown below\n",
    "\n",
    "\n",
    "    StreamSpecification={'StreamEnabled': True,\n",
    "                         'StreamViewType': 'NEW_AND_OLD_IMAGES' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dynamodb_table(table_name, key_name,KeyType):\n",
    "    try:\n",
    "        response = client.describe_table(TableName=table_name)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(\"DynamoDB table '\" + table_name + \"' does not appear to exist, creating...\")\n",
    "        table = dynamodb.create_table(\n",
    "                    TableName = table_name,\n",
    "                    KeySchema = [ { 'AttributeName': key_name,\n",
    "                                    'KeyType': 'HASH'  } ], # Partition key\n",
    "                    AttributeDefinitions = [ \n",
    "                                  { 'AttributeName': key_name,\n",
    "                                  'AttributeType': KeyType \n",
    "                                  } ],\n",
    "                    ProvisionedThroughput = { 'ReadCapacityUnits': 1,\n",
    "                                              'WriteCapacityUnits': 1 },\n",
    "                    StreamSpecification={\n",
    "                                            'StreamEnabled': True,\n",
    "                                            'StreamViewType': 'NEW_AND_OLD_IMAGES'\n",
    "                                        }\n",
    "                )\n",
    "        # Wait until the table exists.\n",
    "        table.meta.client.get_waiter('table_exists').wait(TableName=table_name) \n",
    "        print(\"DynamoDB table '\" + table_name + \"' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dynamodb_table(table_name,\"courseId\",\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Write down the stream ARN. You need this in the next step when you associate the stream with your Lambda function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details of DynamoDB cluster\n",
    "response = client.describe_table(\n",
    "    TableName=table_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:dynamodb:us-east-1:714861692883:table/skaf48dsa_courses/stream/2017-11-09T21:49:43.128'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ARN of stream enabled on dsa_courses dynamodb table.\n",
    "response[\"Table\"][\"LatestStreamArn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell if you want to delete an event source mapping\n",
    "\n",
    "# response = lamb.delete_event_source_mapping(\n",
    "#     UUID='050ab64f-b533-4beb-832e-cd129d938ef7'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an Event Source in AWS Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below cell calling create_mapping function. After the cell executes, capture the UUID. We need this UUID to refer to the event source mapping in any commands, for example, when deleting the event source mapping.\n",
    "\n",
    "If the even source mapping already exists then its ARN is stored in source variable. If not an exception is raised. In the exception we are creating an event source and storing the ARN of the same in source variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    source = lamb.list_event_source_mappings(FunctionName=lambda_name,\n",
    "                                           EventSourceArn=response[\"Table\"][\"LatestStreamArn\"])['EventSourceMappings']\n",
    "except:\n",
    "    source = lamb.create_event_source_mapping(FunctionName=lambda_name, \n",
    "                                              EventSourceArn=response[\"Table\"][\"LatestStreamArn\"],\n",
    "                                              Enabled=True,\n",
    "                                              StartingPosition='TRIM_HORIZON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Setup\n",
    "\n",
    "You're all done! \n",
    "\n",
    "Add, update, delete items to the table dsa_courses DynamoDB table. DynamoDB writes records of these actions to the stream.\n",
    "\n",
    "AWS Lambda polls the stream and when it detects updates to the stream, it invokes your Lambda function by passing in the event data it finds in the stream.\n",
    "\n",
    "The lambda function executes and creates logs in Amazon CloudWatch.\n",
    "\n",
    "Lets go ahead and put a record in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert a record into the database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
       "   'content-length': '2',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'date': 'Thu, 09 Nov 2017 22:03:58 GMT',\n",
       "   'server': 'Server',\n",
       "   'x-amz-crc32': '2745614147',\n",
       "   'x-amzn-requestid': 'A2J8N84GD09P81BVPB2RHRBD53VV4KQNSO5AEMVJF66Q9ASUAAJG'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': 'A2J8N84GD09P81BVPB2RHRBD53VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.put_item(\n",
    "   Item={\n",
    "        'courseName': 'Cloud computing',\n",
    "        'courseId': 8635,\n",
    "        'credits': 3,\n",
    "        'isMandatory':'yes'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
       "   'content-length': '2',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'date': 'Thu, 09 Nov 2017 22:04:24 GMT',\n",
       "   'server': 'Server',\n",
       "   'x-amz-crc32': '2745614147',\n",
       "   'x-amzn-requestid': 'QPJK7CJ3NCJ4BUNAUSEB3KMRFFVV4KQNSO5AEMVJF66Q9ASUAAJG'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': 'QPJK7CJ3NCJ4BUNAUSEB3KMRFFVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.put_item(\n",
    "   Item={\n",
    "        'courseName': 'Statmath',\n",
    "        'courseId': 8610,\n",
    "        'credits': 3,\n",
    "        'isMandatory':'yes'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the logs\n",
    "\n",
    "\n",
    "So for the record that is pushed into the table, lambda function created a log for a change that happaned on the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/dynamodb_trigger.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the table\n",
    "\n",
    "Delete the table by running below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = client.delete_table(\n",
    "    TableName=table_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore below cell. It is for troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# DDB = boto3.resource('dynamodb').Table('dsa_courses')\n",
    "\n",
    "# def lambda_handler(event, context):\n",
    "#     records = event['Records']\n",
    "#     print(\"Received %s records\" % len(records))\n",
    "\n",
    "#     for record in records:\n",
    "#         print(record)\n",
    "\n",
    "#         # if new record or update\n",
    "#         if record['eventName'].upper() in {'INSERT', 'MODIFY'}:\n",
    "\n",
    "#             # primary key\n",
    "#             record_id = record['dynamodb']['Keys']['Id']['S']\n",
    "\n",
    "#             # init local vars\n",
    "#             old_email = old_is_personal = new_email = new_is_personal = None\n",
    "\n",
    "#             # new and old images\n",
    "#             old_image = record['dynamodb'].get('OldImage') or {}\n",
    "#             new_image = record['dynamodb'].get('NewImage') or {}\n",
    "\n",
    "#             # old values (optional, only on update)\n",
    "#             if 'Email' in old_image:\n",
    "#                 old_email = old_image['Email']['S']\n",
    "#             if 'IsPersonalEmail' in old_image:\n",
    "#                 old_is_personal = old_image['IsPersonalEmail']['BOOL']\n",
    "\n",
    "#             # new values\n",
    "#             if 'Email' in new_image:\n",
    "#                 new_email = new_image['Email']['S']\n",
    "#                 new_is_personal = is_personal_email(new_email)\n",
    "\n",
    "#             # avoid recursion on update and write only if strictly needed\n",
    "#             if old_email != new_email and old_is_personal != new_is_personal:\n",
    "#                 update_record(record_id, new_is_personal)\n",
    "\n",
    "#     print(\"Processed %s records\" % len(records))\n",
    "\n",
    "\n",
    "# def update_record(record_id, is_personal):\n",
    "#     print(\"Updating %s: IsPersonalEmail=%s\" % (record_id, is_personal))\n",
    "#     DDB.update_item(\n",
    "#         Key={'Id': record_id},\n",
    "#         UpdateExpression='SET IsPersonalEmail = :val',\n",
    "#         ExpressionAttributeValues={':val': is_personal or False},\n",
    "#     )\n",
    "\n",
    "\n",
    "# def is_personal_email(email):\n",
    "#     domains = {\"gmail.com\", \"outlook.com\", \"hotmail.com\"}\n",
    "#     return any(email.endswith(domain) for domain in domains)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
