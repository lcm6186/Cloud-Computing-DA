{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "You have seen machine learning (ML) in a variety of settings already throughout the curriculum. \n",
    "ML can be defined as a field of computer science that aims at exploring the construction of algorithms and models that can learn from data(often referred to as Ground Truth, in the case of supervised ML to help you identify patterns, and make data-driven decisions\n",
    "\n",
    "\n",
    "The following diagram is a simplified view of typical phases of the ML process in a production environment.\n",
    "\n",
    "\n",
    "<img src=\"../images/ML.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a logical perspective, the following is part of every ML process:\n",
    "\n",
    "- **Obtain training data** - You either build your own dataset, or locate ready-to-use publicly available data. The training data is used as as input for the training phase. You will address this in the next Lab Step. \n",
    "\n",
    "\n",
    "- **Train your model** - This is an offline phase that often requires a lot of time. This phase corresponds with the _Learning Processing_ part of the diagram above.\n",
    "\n",
    "\n",
    "- **Store your model** - This is usually a large matrix of numbers, based on the model complexity and the number of input features. This phase corresponds with the _Model_ part of the diagram above.\n",
    "\n",
    "\n",
    "- **Evaluate your model using part of your dataset** - This is needed to verify whether your model behaves well with new data or not. The evaluation phase can be iterative, and effectively sits between the _Learning Processing_ and _Model_ parts of the diagram above. \n",
    "\n",
    "\n",
    "- **Deploy and use your model for real-time predictions** - By this time in the process, usually several tests have been run and evaluated based on different data sets. At this point you are narrowing it down to one and deploying it. The processing itself is often quite fast, and in some use cases even run on low-power devices such as a smartphone. In this Amazon ML lab you will use AWS APIs. This phase corresponds to the _Predicting Processing_ in the diagram above. \n",
    "\n",
    "<br>\n",
    "In this notebook, we will a create a Machine Learning model for IRIS data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granting Amazon ML Permissions to Read Your Data from Amazon S3\n",
    "\n",
    "To create a datasource object from your input data in Amazon S3, you must grant Amazon ML the following permissions to the S3 location where your input data is stored.\n",
    "\n",
    "Use get_bucket_acl() method to know the access policies attached with the bucket. Access control lists (ACLs) are one of the resource-based access policy options that you can use to manage access to your buckets and objects. You can use ACLs to grant basic read/write permissions to other AWS accounts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### SET THE FOLLOWING PARAMETERS ###################################################\n",
    "#***********************************************************************************\n",
    "#Set the AWS Region\n",
    "region = 'us-east-1'\n",
    "\n",
    "#Set the AWS Access ID (Given to you buy the DSA staff)\n",
    "access_id = 'AKIA2M4ITY7JQWGANH3B'  \n",
    "\n",
    "#Set the AWS Access Key (Given to you buy the DSA staff)\n",
    "access_key = 'PehA8Lji/KXz7Bw+llaHd4cffXXEedXC8zbhFH+T'\n",
    "\n",
    "#Change the data source id to include your pawprint\n",
    "datasource_id = 'irisdata_dsa_lcmhng'\n",
    "\n",
    "# Change the pawprint portion of the output URL below to use  your actual pawprint\n",
    "s3_output_url = \"s3://dsabucket.module4/pawprint/\"  # Give your pawprint here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"S3NHDW8JHX7Z6E4G\",\n",
      "    \"HostId\": \"avymbZRhZnzWCq47VVQmDVfqNCBlyNybdcGqS2f5oPFT3LJ1oc4eSC3EkCsv7AaaO0XbQ2Vw8qM=\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"x-amz-id-2\": \"avymbZRhZnzWCq47VVQmDVfqNCBlyNybdcGqS2f5oPFT3LJ1oc4eSC3EkCsv7AaaO0XbQ2Vw8qM=\",\n",
      "      \"x-amz-request-id\": \"S3NHDW8JHX7Z6E4G\",\n",
      "      \"date\": \"Wed, 10 Nov 2021 02:00:26 GMT\",\n",
      "      \"content-type\": \"application/xml\",\n",
      "      \"transfer-encoding\": \"chunked\",\n",
      "      \"server\": \"AmazonS3\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"Owner\": {\n",
      "    \"DisplayName\": \"dsamasters\",\n",
      "    \"ID\": \"dd6b47de89624f8f1cdfe158faff7cba3652f079c0f8e9b3e8e637f300ebfe6f\"\n",
      "  },\n",
      "  \"Grants\": [\n",
      "    {\n",
      "      \"Grantee\": {\n",
      "        \"DisplayName\": \"dsamasters\",\n",
      "        \"ID\": \"dd6b47de89624f8f1cdfe158faff7cba3652f079c0f8e9b3e8e637f300ebfe6f\",\n",
      "        \"Type\": \"CanonicalUser\"\n",
      "      },\n",
      "      \"Permission\": \"FULL_CONTROL\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "data_s3_url = \"s3://dsabucket.module4/iris_data/irisdata.csv\"\n",
    "\n",
    "# Call to S3 to retrieve the policy for the given bucket\n",
    "s3 = boto3.client('s3', \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "bucket_name = 'dsabucket.module4'\n",
    "# get_bucket_acl() method gets the access control policy for the specified bucket.\n",
    "# We want to use dsabucket.module4 for storing the data. Check and add more policies so AWS ML service can access the dataset\n",
    "result = s3.get_bucket_acl(Bucket=bucket_name)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below cell we are creating a JSON object defining the access rules who can access dsabucket.module4. \n",
    "\n",
    "The policy is separated into two parts because the ListBucket action requires permissions on the bucket while the other actions require permissions on the objects in the bucket. We used two different Amazon Resource Names (ARNs) to specify bucket-level and object-level permissions. The first Resource element specifies arn:aws:s3:::dsabucket.module4 for the ListBucket action so that applications can list all objects in the test bucket. The second Resource element specifies arn:aws:s3:::dsabucket.module4/* for the GetObject, PutObject, and DeletObject actions so that applications can read, write, and delete any objects in the test bucket.\n",
    "\n",
    "We did not combine the two ARNs by using a wildcard, such as arn:aws:s3:::dsabucket.module4*. Even though this ARN would grant permissions for all actions in a single statement, it is broader and grants access to any bucket and objects in that bucket that begin with dsabucket.module4, like dsabucket.module4-bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '58XZRDB1YNC2QBPW',\n",
       "  'HostId': 'JfkA1Rfor1uv2mo4Pv//ut0/cZ39B3FCvpmX1XGBBo4lPJ8VIscJvhjriPuQL48KGRvbnT1Q4ms=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'JfkA1Rfor1uv2mo4Pv//ut0/cZ39B3FCvpmX1XGBBo4lPJ8VIscJvhjriPuQL48KGRvbnT1Q4ms=',\n",
       "   'x-amz-request-id': '58XZRDB1YNC2QBPW',\n",
       "   'date': 'Wed, 10 Nov 2021 02:02:52 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'dsabucket.module4'\n",
    "\n",
    "bucket_policy= {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": { \"Service\": \"machinelearning.amazonaws.com\"},\n",
    "      \"Action\": [\"s3:ListBucket\"],\n",
    "      \"Resource\": [\"arn:aws:s3:::dsabucket.module4\"]\n",
    "    },\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": { \"Service\": \"machinelearning.amazonaws.com\"},\n",
    "      \"Action\": \"s3:PutObjectAcl\",\n",
    "      \"Resource\": \"arn:aws:s3:::dsabucket.module4/*\"\n",
    "    },\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": { \"Service\": \"machinelearning.amazonaws.com\"},\n",
    "      \"Action\": [\n",
    "        \"s3:PutObject\",\n",
    "        \"s3:GetObject\",\n",
    "        \"s3:DeleteObject\"\n",
    "      ],\n",
    "      \"Resource\": [\"arn:aws:s3:::dsabucket.module4/*\"]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the policy to a JSON string\n",
    "bucket_policy = json.dumps(bucket_policy)\n",
    "\n",
    "# Set the new policy on the given bucket\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=bucket_policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s3:GetObject applies to the objects in the bucket so the Resource is correct: \"Resource\": \"arn:aws:s3:::my-bucket/*\".\n",
    "\n",
    "s3:ListBucket applies to the Bucket itself and so the Resource should be \"Resource\": \"arn:aws:s3:::my-bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset selection and manipulation\n",
    "\n",
    "Data manipulation prior to using Machine Learning is very common. Below code cell has all steps to create a data source that an AWS ML model can use. Whether your input data comes from your own database, or from an open dataset, most of the time you need to manipulate the raw data. There can be several reasons for this, including:\n",
    "\n",
    "- **Data normalization (or feature scaling)** - Fortunately Amazon ML takes care of this for you, but you do want to avoid unbalanced contributions of your input features, in case their values span very different ranges.\n",
    "\n",
    "\n",
    "- **Feature selection (or subset selection)** - Once again, you don't need to worry about this when using Amazon ML, although removing redundant or irrelevant features before training your model can make it faster and more accurate.\n",
    "\n",
    "\n",
    "- **Data formatting** - Recall that models are big matrices of data. You always need to feed them with a suitable input format. In this Lab you will use a basic CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('machinelearning', region_name='us-east-1', \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "\n",
    "response = client.create_data_source_from_s3(\n",
    "    DataSourceId=datasource_id,\n",
    "    DataSourceName='iris data',\n",
    "    DataSpec={\n",
    "        'DataLocationS3': 's3://dsabucket.module4/iris_data/irisdata.csv',\n",
    "        'DataSchema': \"\"\"{ \"version\": \"1.0\", \n",
    "                         \"targetFieldName\": \"class\",\n",
    "                         \"dataFormat\": \"CSV\", \n",
    "                         \"dataFileContainsHeader\": \"true\", \n",
    "                         \"attributes\": \n",
    "                            [  \n",
    "                                { \"fieldName\": \"sepal_length\", \"fieldType\": \"NUMERIC\" }, \n",
    "                                { \"fieldName\": \"sepal_width\",  \"fieldType\": \"NUMERIC\" },  \n",
    "                                { \"fieldName\": \"petal_length\", \"fieldType\": \"NUMERIC\" }, \n",
    "                                { \"fieldName\": \"petal_width\",  \"fieldType\": \"NUMERIC\" }, \n",
    "                                { \"fieldName\": \"class\",        \"fieldType\": \"CATEGORICAL\" }\n",
    "                            ]\n",
    "                      }\"\"\"\n",
    "              },\n",
    "    ComputeStatistics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a MLModel using the DataSource and the recipe as information sources.\n",
    "\n",
    "CreateMLModel is an asynchronous operation. In response to CreateMLModel , Amazon Machine Learning (Amazon ML) immediately returns and sets the MLModel status to PENDING .After the MLModel has been created and is ready for use, Amazon ML sets the status to COMPLETED.\n",
    "\n",
    "GetMLModel operation is used to check the progress of the MLModel during the creation operation.\n",
    "\n",
    "CreateMLModel requires a DataSource with computed statistics, which can be created by setting ComputeStatistics to true in CreateDataSourceFromS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are \n",
    "schema_fn = \"iris.schema\"\n",
    "recipe_fn = \"recipe.json\"\n",
    "name = \"iris classification\"\n",
    "created_model_id=\"\"\n",
    "train_ds_id=\"\"\n",
    "test_ds_id=\"\"\n",
    "eval_id=\"\"\n",
    "\n",
    "\n",
    "# create AWS machine learning clinet\n",
    "ml = boto3.client('machinelearning', region_name='us-east-1', \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data_s3_url, schema_fn, recipe_fn, name, train_percent=70):\n",
    "    \"\"\"Creates all the objects needed to build an ML Model & evaluate its quality.\n",
    "    \"\"\"\n",
    "    # ml - aws machine learning object\n",
    "    # data_s3_url - S3 location where input data is located\n",
    "    # schema_fn - schema of IRIS dataset\n",
    "    # train_percent - How much % data you want in training set\n",
    "    # name - name of the ML model\n",
    "    # recipe_fn - Its a JSON file that describes the attributes in the dataset\n",
    "    \n",
    "    # Create train and test data sources\n",
    "    (train_ds_id, test_ds_id) = create_data_sources(ml, data_s3_url, schema_fn, train_percent, name)\n",
    "    \n",
    "    # Create the model using train dataset\n",
    "    ml_model_id = create_model(ml, train_ds_id, recipe_fn, name)\n",
    "    \n",
    "    eval_id = create_evaluation(ml, ml_model_id, test_ds_id, name)\n",
    "\n",
    "    return ml_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def create_data_sources(ml, data_s3_url, schema_fn, train_percent, name):\n",
    "    \"\"\"Create two data sources.  One with (train_percent)% of the data,\n",
    "    which will be used for training.  The other one with the remainder of the data,\n",
    "    which is commonly called the \"test set\" and will be used to evaluate the quality\n",
    "    of the ML Model.\n",
    "    \"\"\"\n",
    "    train_ds_id = 'ds-' + str(uuid.uuid4())\n",
    "    spec = {\n",
    "        \"DataLocationS3\": data_s3_url,\n",
    "        \"DataRearrangement\": json.dumps({\n",
    "            \"splitting\": {\n",
    "                \"percentBegin\": 0,\n",
    "                \"percentEnd\": train_percent,\n",
    "                \"strategy\":\"random\"\n",
    "            },\n",
    "        }),\n",
    "        \"DataSchema\": open(schema_fn).read(),\n",
    "    }\n",
    "    \n",
    "    ml.create_data_source_from_s3(\n",
    "        DataSourceId=train_ds_id,\n",
    "        DataSpec=spec,\n",
    "        DataSourceName=name + \" - training split\",\n",
    "        ComputeStatistics=True\n",
    "    )    \n",
    "    \n",
    "    print(\"Created training data set %s\" % train_ds_id)\n",
    "\n",
    "    test_ds_id = 'ds-' + str(uuid.uuid4())\n",
    "    spec['DataRearrangement'] = json.dumps({\n",
    "        \"splitting\": {\n",
    "            \"percentBegin\": train_percent,\n",
    "            \"percentEnd\": 100,\n",
    "            \"strategy\":\"random\"\n",
    "        }\n",
    "    })\n",
    "    ml.create_data_source_from_s3(\n",
    "        DataSourceId=test_ds_id,\n",
    "        DataSpec=spec,\n",
    "        DataSourceName=name + \" - testing split\",\n",
    "        ComputeStatistics=True\n",
    "    )\n",
    "    print(\"Created test data set %s\" % test_ds_id)\n",
    "    return (train_ds_id, test_ds_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are calling create_ml_model() method inside create_model() method definition for creating a new MLModel using the DataSource and the recipe as information sources.\n",
    "\n",
    "\n",
    "Syntax: \n",
    "\n",
    "    response = client.create_ml_model(\n",
    "        MLModelId='string',\n",
    "        MLModelName='string',\n",
    "        MLModelType='REGRESSION'|'BINARY'|'MULTICLASS',\n",
    "        Parameters={\n",
    "            'string': 'string'\n",
    "        },\n",
    "        TrainingDataSourceId='string',\n",
    "        Recipe='string',\n",
    "        RecipeUri='string'\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "- **sgd.maxMLModelSizeInBytes** - The maximum allowed size of the model. Depending on the input data, the size of the model might affect its performance. The value is an integer that ranges from 100000 to 2147483648 . The default value is 33554432 .\n",
    "\n",
    "\n",
    "- **sgd.maxPasses** - The number of times that the training process traverses the observations to build the MLModel . The value is an integer that ranges from 1 to 10000 . The default value is 10 .\n",
    "\n",
    "\n",
    "- **sgd.l1RegularizationAmount** - The coefficient regularization L1 norm. It controls overfitting the data by penalizing large coefficients. This tends to drive coefficients to zero, resulting in a sparse feature set. If you use this parameter, start by specifying a small value, such as 1.0E-08 . The value is a double that ranges from 0 to MAX_DOUBLE . The default is to not use L1 normalization. This parameter can't be used when L2 is specified. Use this parameter sparingly.\n",
    "\n",
    "\n",
    "- **Recipe (string)** -- The data recipe for creating the MLModel . You must specify either the recipe or its URI. If you don't specify a recipe or its URI, Amazon ML creates a default.\n",
    "\n",
    "\n",
    "- **RecipeUri (string)** -- The Amazon Simple Storage Service (Amazon S3) location and file name that contains the MLModel recipe. You must specify either the recipe or its URI. If you don't specify a recipe or its URI, Amazon ML creates a default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(ml, train_ds_id, recipe_fn, name):\n",
    "    \"\"\"Creates an ML Model object, which begins the training process.\n",
    "The quality of the model that the training algorithm produces depends\n",
    "primarily on the data, but also on the hyper-parameters specified\n",
    "in the parameters map, and the feature-processing recipe.\n",
    "    \"\"\"\n",
    "    created_model_id = 'ml-' + str(uuid.uuid4())\n",
    "    ml.create_ml_model(\n",
    "        MLModelId=created_model_id,\n",
    "        MLModelName=name + \" model\",\n",
    "        MLModelType=\"MULTICLASS\",  # we're predicting True/False values\n",
    "        Parameters={\n",
    "            # Refer to the \"Machine Learning Concepts\" documentation\n",
    "            # for guidelines on tuning your model\n",
    "            \"sgd.maxPasses\": \"100\",\n",
    "            \"sgd.maxMLModelSizeInBytes\": \"104857600\",  # 100 MiB\n",
    "            \"sgd.l2RegularizationAmount\": \"1e-4\",\n",
    "        },\n",
    "        Recipe=open(recipe_fn).read(),\n",
    "        TrainingDataSourceId=train_ds_id\n",
    "    )\n",
    "    print(\"Created ML Model %s\" % created_model_id)\n",
    "    return created_model_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation(ml, model_id, test_ds_id, name):\n",
    "    eval_id = 'ev-' + str(uuid.uuid4())\n",
    "    ml.create_evaluation(\n",
    "        EvaluationId=eval_id,\n",
    "        EvaluationName=name + \" evaluation\",\n",
    "        MLModelId=model_id,\n",
    "        EvaluationDataSourceId=test_ds_id\n",
    "    )\n",
    "    print(\"Created Evaluation %s\" % eval_id)\n",
    "    return eval_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "<a id='creating_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training data set ds-92cdf442-294b-4e7b-8381-0af5c9d8f04a\n",
      "Created test data set ds-286e924a-a5dc-48ca-b18d-93959c06728e\n",
      "Created ML Model ml-76e72c9e-45b0-4727-8e81-66ae52453590\n",
      "Created Evaluation ev-58ada962-809e-4f3a-87a5-f0ce98277210\n"
     ]
    }
   ],
   "source": [
    "model_id = build_model(data_s3_url, schema_fn, recipe_fn, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the model but it takes some time for the model to be built and ready to use. Below poll function will keep polling until the status changes to anything under ['COMPLETED', 'FAILED', 'INVALID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_until_completed(ml, model_id):\n",
    "    delay = 2\n",
    "    while True:\n",
    "        model = ml.get_ml_model(MLModelId=model_id)\n",
    "        status = model['Status']\n",
    "        message = model.get('Message', '')\n",
    "        now = str(datetime.datetime.now().time())\n",
    "        print(\"Model %s is %s (%s) at %s\" % (model_id, status, message, now))\n",
    "        if status in ['COMPLETED', 'FAILED', 'INVALID']:\n",
    "            break\n",
    "\n",
    "        # exponential backoff with jitter\n",
    "        delay *= random.uniform(1.1, 2.0)\n",
    "        time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is PENDING () at 20:17:09.642442\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is PENDING () at 20:17:12.206976\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is PENDING () at 20:17:17.274315\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is PENDING () at 20:17:25.830105\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is PENDING () at 20:17:41.673346\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is PENDING () at 20:18:10.478218\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is PENDING () at 20:18:56.790081\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is INPROGRESS () at 20:20:08.453534\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is INPROGRESS (Current Step: TRAINING (1/1) Current Iteration: (100/100) 100%) at 20:21:48.077017\n",
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is COMPLETED () at 20:23:39.695900\n"
     ]
    }
   ],
   "source": [
    "poll_until_completed(ml, model_id=model_id)  # Can't use it until it's COMPLETED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the model is created. Once it is in completed status, you can run create_realtime_endpoint() function in below code cell to create end point for the model for making realtime predictions on new test data. The endpoint contains the URI of the MLModel. That is, the location to send real-time prediction requests for the specified MLModel.\n",
    "\n",
    "## Note:\n",
    "Make sure to check and update the model id in below cell with the latest machine learning model we created above to create the end point. \n",
    "\n",
    "[Go to this cell to make sure the ML id is same](#creating_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.create_realtime_endpoint(\n",
    "    MLModelId=model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MLModelId': 'ml-76e72c9e-45b0-4727-8e81-66ae52453590',\n",
      " 'RealtimeEndpointInfo': {'CreatedAt': datetime.datetime(2021, 11, 9, 20, 24, 21, 405000, tzinfo=tzlocal()),\n",
      "                          'EndpointStatus': 'READY',\n",
      "                          'EndpointUrl': 'https://realtime.machinelearning.us-east-1.amazonaws.com',\n",
      "                          'PeakRequestsPerSecond': 200},\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '235',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Wed, 10 Nov 2021 02:32:02 GMT',\n",
      "                                      'x-amzn-requestid': '7780b59d-82e1-4c48-9bf1-3785e415780c'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '7780b59d-82e1-4c48-9bf1-3785e415780c',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "\n",
    "Lets evaluate the model by checking the predictive ability. The test record present in [iris_record.csv](iris_record.csv)(csv file is present in current working directory /module3/labs/iris_recrd.csv) has one record whose species is virginica. Lets test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for a minute before running below cell. The create_realtime_endpoint() method in above cell will create an endpoint for a making predictions and it will take some time in updating the status of the endpoint.\n",
    "\n",
    "## Note:\n",
    "\n",
    "Make sure the end point in below cell matches with the endpoint given in the response output of create_realtime_endpoint() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Prediction\": {\n",
      "    \"predictedLabel\": \"virginica\",\n",
      "    \"predictedScores\": {\n",
      "      \"setosa\": 0.17459960281848907,\n",
      "      \"versicolor\": 0.24952912330627441,\n",
      "      \"virginica\": 0.5758712887763977\n",
      "    },\n",
      "    \"details\": {\n",
      "      \"Algorithm\": \"SGD\",\n",
      "      \"PredictiveModelType\": \"MULTICLASS\"\n",
      "    }\n",
      "  },\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"08aef466-ef8f-4ba4-913f-e31074520ab1\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"x-amzn-requestid\": \"08aef466-ef8f-4ba4-913f-e31074520ab1\",\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"content-length\": \"223\",\n",
      "      \"date\": \"Wed, 10 Nov 2021 02:25:49 GMT\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n",
      "******************************\n",
      "Its a virginica.\n"
     ]
    }
   ],
   "source": [
    "# from boto3.session import Session\n",
    "import json\n",
    " \n",
    "# session = Session(aws_access_key_id=access_id, aws_secret_access_key=secret_key)\n",
    " \n",
    "try:\n",
    "    model = ml.get_ml_model(MLModelId=model_id)\n",
    "    prediction_endpoint = 'https://realtime.machinelearning.us-east-1.amazonaws.com'\n",
    " \n",
    "    with open('iris_record.csv') as f:\n",
    "        record_str = f.readline()\n",
    " \n",
    "    record = {}\n",
    "    for index,val in enumerate(record_str.split(',')):\n",
    "        record['Var%03d' % (index+1)] = val\n",
    " \n",
    "    response = ml.predict(MLModelId=model_id, Record=record, PredictEndpoint=prediction_endpoint)\n",
    "    print(json.dumps(response, indent=2))\n",
    "    label = response.get('Prediction').get('predictedLabel')\n",
    "    print(\"*\"*30)\n",
    "    print(\"Its a %s.\" % label)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did predict the leaf belongs to the species Virginica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Predictions\n",
    "\n",
    "Below code cells demonstrate how to use an ML Model, to kick off a batch prediction job, which uses the ML Model to generate predictions on new data. It takes the ML Model and test data to make the predictions. create_batch_prediction() method writes the prediction results to the supplied S3 location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL of the sample data in S3\n",
    "\n",
    "def use_model(ml, model_id, output_s3, inputdatasource_id):\n",
    "    \"\"\"Creates all the objects needed to build an ML Model & evaluate its quality.\n",
    "    \"\"\"\n",
    "\n",
    "    poll_until_completed(ml, model_id)  # Can't use it until it's COMPLETED\n",
    "#     ml.update_ml_model(MLModelId=model_id, ScoreThreshold=threshold)\n",
    "    print(\"Set score threshold for %s to %.2f\" % (model_id, threshold))\n",
    "\n",
    "    bp_id = 'bp-' + str(uuid.uuid4())\n",
    "    ml.create_batch_prediction(\n",
    "        BatchPredictionId=bp_id,\n",
    "        BatchPredictionName=\"Batch Prediction for marketing sample\",\n",
    "        MLModelId=model_id,\n",
    "        BatchPredictionDataSourceId=inputdatasource_id,\n",
    "        OutputUri=output_s3\n",
    "    )\n",
    "    print(\"Created Batch Prediction %s\" % bp_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the method use_model(), to make the batch predictions. Results will be written to the location \"s3://dsabucket.module4/\"\n",
    "\n",
    "# Note:\n",
    " \n",
    "Give your pawprint in below cell where it is commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ml-76e72c9e-45b0-4727-8e81-66ae52453590 is COMPLETED () at 20:34:30.225967\n",
      "Set score threshold for ml-76e72c9e-45b0-4727-8e81-66ae52453590 to 0.70\n",
      "Created Batch Prediction bp-7f525300-825d-415e-a366-c262c866cccf\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import boto3\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "threshold = 0.7\n",
    "\n",
    "# NOTE!!!! - You Need to change this to the ID of the test data set shown below \"Create The Model\" several cells above\n",
    "# UNSCORED_DATA_ID = \"ds-ed65601e-3e60-439d-a1e7-f2327d3d3139\" # Replace this Example-ID by the ID of the test data set\n",
    "UNSCORED_DATA_ID = \"ds-286e924a-a5dc-48ca-b18d-93959c06728e\"\n",
    "\n",
    "# parsed_url = urlparse.parse(s3_output_url)\n",
    "\n",
    "use_model(ml, model_id, s3_output_url, UNSCORED_DATA_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for 2 minutes before running below cell. List the objects in the S3 bucket \"s3://dsabucket.module4/$<your pawprint>$\" to get the address of the results directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aca2zb/batch-prediction/bp-12b29cce-78bc-4ed3-a57c-63673a369cae.manifest\n",
      "\n",
      "aca2zb/batch-prediction/result/bp-12b29cce-78bc-4ed3-a57c-63673a369cae-irisdata.csv.gz\n",
      "\n",
      "ajky9b/batch-prediction/bp-d20414a6-31a8-4726-b532-f3085913db51.manifest\n",
      "\n",
      "ajky9b/batch-prediction/result/bp-d20414a6-31a8-4726-b532-f3085913db51-irisdata.csv.gz\n",
      "\n",
      "avgnzd/batch-prediction/bp-fd86a58d-9733-453b-be4c-00ee2984d8f2.manifest\n",
      "\n",
      "avgnzd/batch-prediction/result/bp-fd86a58d-9733-453b-be4c-00ee2984d8f2-irisdata.csv.gz\n",
      "\n",
      "bbb9hy/batch-prediction/bp-a8545530-7f6f-4f7b-9f8c-8e5e627ec590.manifest\n",
      "\n",
      "bbb9hy/batch-prediction/result/bp-a8545530-7f6f-4f7b-9f8c-8e5e627ec590-irisdata.csv.gz\n",
      "\n",
      "bmgwd9/batch-prediction/bp-e9410f78-1d62-4548-b8fc-1aba4e8dcad6.manifest\n",
      "\n",
      "bmgwd9/batch-prediction/result/bp-e9410f78-1d62-4548-b8fc-1aba4e8dcad6-irisdata.csv.gz\n",
      "\n",
      "bprh4/batch-prediction/bp-fc656a12-8c4e-4e7a-b69a-6512cc22012e.manifest\n",
      "\n",
      "bprh4/batch-prediction/result/bp-fc656a12-8c4e-4e7a-b69a-6512cc22012e-irisdata.csv.gz\n",
      "\n",
      "cjgwx7/batch-prediction/bp-f4fe3c88-7f63-4640-b839-6fc7b9774d31.manifest\n",
      "\n",
      "cjgwx7/batch-prediction/result/bp-f4fe3c88-7f63-4640-b839-6fc7b9774d31-irisdata.csv.gz\n",
      "\n",
      "cjwxbb/batch-prediction/bp-2f3ed182-d477-466d-8a20-fa2d73b9bc4b.manifest\n",
      "\n",
      "cjwxbb/batch-prediction/result/bp-2f3ed182-d477-466d-8a20-fa2d73b9bc4b-irisdata.csv.gz\n",
      "\n",
      "clayb2/batch-prediction/bp-b6c2a26b-bf1b-43eb-b95e-48c0772016a3.manifest\n",
      "\n",
      "clayb2/batch-prediction/result/bp-b6c2a26b-bf1b-43eb-b95e-48c0772016a3-irisdata.csv.gz\n",
      "\n",
      "dcphw2/batch-prediction/bp-c1cd87ad-69d5-458b-83be-f5f6257d0935.manifest\n",
      "\n",
      "dcphw2/batch-prediction/result/bp-c1cd87ad-69d5-458b-83be-f5f6257d0935-irisdata.csv.gz\n",
      "\n",
      "dgyw5/batch-prediction/bp-e48baad4-4725-45ab-9c2a-bd95968afa52.manifest\n",
      "\n",
      "dgyw5/batch-prediction/result/bp-e48baad4-4725-45ab-9c2a-bd95968afa52-irisdata.csv.gz\n",
      "\n",
      "dlmtk8/batch-prediction/bp-1db56162-5c09-468c-aee6-fdc8c43d9950.manifest\n",
      "\n",
      "dlmtk8/batch-prediction/result/bp-1db56162-5c09-468c-aee6-fdc8c43d9950-irisdata.csv.gz\n",
      "\n",
      "dlr6w3/batch-prediction/bp-a2749482-28c2-4cda-8ac7-77399f34b7f1.manifest\n",
      "\n",
      "dlr6w3/batch-prediction/result/bp-a2749482-28c2-4cda-8ac7-77399f34b7f1-irisdata.csv.gz\n",
      "\n",
      "egc4x/batch-prediction/bp-5675955e-91dd-4af6-ad1b-f6d936072cf6.manifest\n",
      "\n",
      "egc4x/batch-prediction/bp-cd8f0fe4-168e-4dcf-a2ea-813ebe99ef70.manifest\n",
      "\n",
      "egc4x/batch-prediction/result/bp-5675955e-91dd-4af6-ad1b-f6d936072cf6-irisdata.csv.gz\n",
      "\n",
      "egc4x/batch-prediction/result/bp-cd8f0fe4-168e-4dcf-a2ea-813ebe99ef70-irisdata.csv.gz\n",
      "\n",
      "hkjmwk/batch-prediction/bp-6c3f7ae9-4022-44a4-b7bd-9c0376842cfc.manifest\n",
      "\n",
      "hkjmwk/batch-prediction/bp-f681fd4d-d399-4e77-b643-553029b0c24d.manifest\n",
      "\n",
      "hkjmwk/batch-prediction/result/bp-6c3f7ae9-4022-44a4-b7bd-9c0376842cfc-irisdata.csv.gz\n",
      "\n",
      "hkjmwk/batch-prediction/result/bp-f681fd4d-d399-4e77-b643-553029b0c24d-irisdata.csv.gz\n",
      "\n",
      "iris_data/\n",
      "\n",
      "iris_data/irisdata.csv\n",
      "\n",
      "jakth2/batch-prediction/bp-1259db51-436c-4d40-ac18-1308587d3e88.manifest\n",
      "\n",
      "jakth2/batch-prediction/result/bp-1259db51-436c-4d40-ac18-1308587d3e88-irisdata.csv.gz\n",
      "\n",
      "jmy83b/batch-prediction/bp-44db0f78-48fd-42a9-a614-0944e9fc249c.manifest\n",
      "\n",
      "jmy83b/batch-prediction/result/bp-44db0f78-48fd-42a9-a614-0944e9fc249c-irisdata.csv.gz\n",
      "\n",
      "jwcp64/batch-prediction/bp-7acca666-16fc-4240-89c5-c94b7a02bc50.manifest\n",
      "\n",
      "jwcp64/batch-prediction/result/bp-7acca666-16fc-4240-89c5-c94b7a02bc50-irisdata.csv.gz\n",
      "\n",
      "kg37m/batch-prediction/bp-2df92f02-020b-451d-8bfc-415cabd7a935.manifest\n",
      "\n",
      "kg37m/batch-prediction/bp-50324ca8-f74d-4a3c-a824-9ac80dd5c4bb.manifest\n",
      "\n",
      "kg37m/batch-prediction/result/bp-2df92f02-020b-451d-8bfc-415cabd7a935-irisdata.csv.gz\n",
      "\n",
      "kg37m/batch-prediction/result/bp-50324ca8-f74d-4a3c-a824-9ac80dd5c4bb-irisdata.csv.gz\n",
      "\n",
      "lem7h2/batch-prediction/bp-60778678-0199-42e8-a7a9-f489b4f62b63.manifest\n",
      "\n",
      "lem7h2/batch-prediction/result/bp-60778678-0199-42e8-a7a9-f489b4f62b63-irisdata.csv.gz\n",
      "\n",
      "mb2dw/batch-prediction/bp-cc595234-711e-48a2-abf7-3662144cdd3a.manifest\n",
      "\n",
      "mb2dw/batch-prediction/result/bp-cc595234-711e-48a2-abf7-3662144cdd3a-irisdata.csv.gz\n",
      "\n",
      "mk7zp/batch-prediction/bp-a8dbbd07-1dce-41b1-9237-280a8a514acc.manifest\n",
      "\n",
      "mk7zp/batch-prediction/result/bp-a8dbbd07-1dce-41b1-9237-280a8a514acc-irisdata.csv.gz\n",
      "\n",
      "mmxyb/batch-prediction/bp-0e03ad86-108e-4c55-b76e-263c921f57b0.manifest\n",
      "\n",
      "mmxyb/batch-prediction/result/bp-0e03ad86-108e-4c55-b76e-263c921f57b0-irisdata.csv.gz\n",
      "\n",
      "neverb/batch-prediction/bp-590cda96-4ea5-4930-a995-8fad3d111572.manifest\n",
      "\n",
      "neverb/batch-prediction/result/bp-590cda96-4ea5-4930-a995-8fad3d111572-irisdata.csv.gz\n",
      "\n",
      "pawprint/batch-prediction/bp-462998d4-f590-4555-bb76-2c2cc9e366bc.manifest\n",
      "\n",
      "pawprint/batch-prediction/bp-690d2b1a-66b4-4f1c-bda5-b60063e45c45.manifest\n",
      "\n",
      "pawprint/batch-prediction/bp-7f525300-825d-415e-a366-c262c866cccf.manifest\n",
      "\n",
      "pawprint/batch-prediction/bp-b9d56559-732e-4908-a728-e1ea21a779ef.manifest\n",
      "\n",
      "pawprint/batch-prediction/bp-ee609407-72d3-4ace-a028-58e14481ff21.manifest\n",
      "\n",
      "pawprint/batch-prediction/result/bp-462998d4-f590-4555-bb76-2c2cc9e366bc-irisdata.csv.gz\n",
      "\n",
      "pawprint/batch-prediction/result/bp-690d2b1a-66b4-4f1c-bda5-b60063e45c45-irisdata.csv.gz\n",
      "\n",
      "pawprint/batch-prediction/result/bp-7f525300-825d-415e-a366-c262c866cccf-irisdata.csv.gz\n",
      "\n",
      "pawprint/batch-prediction/result/bp-b9d56559-732e-4908-a728-e1ea21a779ef-irisdata.csv.gz\n",
      "\n",
      "pawprint/batch-prediction/result/bp-ee609407-72d3-4ace-a028-58e14481ff21-irisdata.csv.gz\n",
      "\n",
      "rc25g/batch-prediction/bp-ce6bf4b5-dd95-424d-bc5d-0a1d68181fcd.manifest\n",
      "\n",
      "rc25g/batch-prediction/result/bp-ce6bf4b5-dd95-424d-bc5d-0a1d68181fcd-irisdata.csv.gz\n",
      "\n",
      "rsgk3/batch-prediction/bp-a36a7b10-bc74-45b2-92d3-892e06b96ab6.manifest\n",
      "\n",
      "rsgk3/batch-prediction/result/bp-a36a7b10-bc74-45b2-92d3-892e06b96ab6-irisdata.csv.gz\n",
      "\n",
      "tdy56/batch-prediction/bp-3ae81ae1-7e11-4876-98d3-9094f5db1ba0.manifest\n",
      "\n",
      "tdy56/batch-prediction/result/bp-3ae81ae1-7e11-4876-98d3-9094f5db1ba0-irisdata.csv.gz\n",
      "\n",
      "tmbkg4/batch-prediction/bp-0cda400b-f1c7-418b-a494-74a236e39888.manifest\n",
      "\n",
      "tmbkg4/batch-prediction/result/bp-0cda400b-f1c7-418b-a494-74a236e39888-irisdata.csv.gz\n",
      "\n",
      "zembmn/batch-prediction/bp-841aad5f-dc1d-445f-988c-50e7339b2891.manifest\n",
      "\n",
      "zembmn/batch-prediction/bp-da9a0bd1-9900-4ce1-be96-e04be11cfd76.manifest\n",
      "\n",
      "zembmn/batch-prediction/result/bp-841aad5f-dc1d-445f-988c-50e7339b2891-irisdata.csv.gz\n",
      "\n",
      "zembmn/batch-prediction/result/bp-da9a0bd1-9900-4ce1-be96-e04be11cfd76-irisdata.csv.gz\n",
      "\n",
      "zp2gz/batch-prediction/bp-0b212e08-f99c-46c9-bf7e-3ebc7e99715f.manifest\n",
      "\n",
      "zp2gz/batch-prediction/result/bp-0b212e08-f99c-46c9-bf7e-3ebc7e99715f-irisdata.csv.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# s3 = boto3.client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for obj in s3.list_objects(Bucket=bucket_name)['Contents']:\n",
    "    print(obj['Key']+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch prediction results are stored in the location \"dsabucket.module4/batch-prediction/result/\". The results are saved as a zip file. Take the zip file, convert it in to a stream of bytes. GzipFile() takes the compresssed file and decompresses it. The final output is in the form of strings. \n",
    "\n",
    "\n",
    "## Note:\n",
    "\n",
    "Fill the blank for the location of prediction results file name.  \n",
    "\n",
    "It looks similar to below\n",
    "\n",
    "    <your pawprint>/batch-prediction/result/bp-335b03ff-fbad-4949-9123-b9564dd0094b-irisdata.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I'm not sure why my pawprint isn't being included, but the below matches the output of what I see above\n",
    "\n",
    "from io import BytesIO\n",
    "from gzip import GzipFile\n",
    "\n",
    "# NOTE!!! - You need to change the key to your prediction results file name shown in the scrollbox above\n",
    "retr = s3.get_object(Bucket=bucket_name, Key='pawprint/batch-prediction/result/bp-7f525300-825d-415e-a366-c262c866cccf-irisdata.csv.gz') # Get the file name from above list objects output\n",
    "\n",
    "bytestream = BytesIO(retr['Body'].read())\n",
    "got_text = GzipFile(None, 'rb', fileobj=bytestream).read().decode('utf-8')\n",
    "type(got_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the string output extracted in above cell into a csv file. These are the predictions from the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "s = io.StringIO(got_text)\n",
    "with open('iris_results.csv', 'w') as f:\n",
    "    for line in s:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file into a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trueLabel    setosa  versicolor  virginica\n",
      "0    setosa  0.999532    0.000201   0.000267\n",
      "1    setosa  0.996606    0.002008   0.001386\n",
      "2    setosa  0.966665    0.016052   0.017282\n",
      "3    setosa  0.998670    0.000660   0.000670\n",
      "4    setosa  0.992480    0.002195   0.005325\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('iris_results.csv', 'r') as file:\n",
    "    df = pd.read_csv(file)\n",
    "#     df.reset_index(inplace=True)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a column for true labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    setosa\n",
       "1    setosa\n",
       "2    setosa\n",
       "3    setosa\n",
       "4    setosa\n",
       "Name: trueLabel, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truelabels=df['trueLabel']\n",
    "truelabels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.idxmax() function expects numerical inputs. The \"trueLabel\" df is of type string. Since we alreday captured true labels in the variable truelabels, delete the column trueLabel from the dataframe \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['trueLabel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities are generated for different classes in the form of predictions. These probabilities indicate the chance of the row belonging to certain species. Use these probabilities to label the predictions. In the next code cell, we are using df.idxmax() function which returns the column name which has the highest value of all rows. \n",
    "\n",
    "Now predictions have the species name predicted for each of the 50 rows in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a confusion matrix using trueLabels and predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0,  9,  4],\n",
       "       [ 0,  0, 16]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(truelabels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(truelabels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There it is. The model built by AWS machine learning service predicted the species with 90% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
