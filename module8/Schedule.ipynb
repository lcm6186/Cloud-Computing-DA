{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - Final Project\n",
    "\n",
    "The structure of the Final Project will follow the build up of the GCP lessons,\n",
    "so this may be the shorter route for most students.\n",
    "\n",
    "\n",
    "### Cloud Analytics\n",
    "\n",
    "![DataScraperStructure_Mini_Project2.png MISSING](./images/DataScraperStructure_Mini_Project2.png)\n",
    "\n",
    "In the last module, we explored various Cloud API from GCP.\n",
    "AWS and other cloud providers also have API for functionalities such as machine learning, vision, and text processing.\n",
    "Additionally, you have seen how you can build VMs and containers to stand up your own compute resources to achieve these things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Specifications:\n",
    "\n",
    "This project should serve as a portfolio example of your capabilities to architect and implement data science pipelines within a cloud environment.\n",
    "\n",
    "#### Ingest Reddit RSS Feed and produce analytical products by following the pipeline below.\n",
    "#### Produce a tabular summary\n",
    "#### Produce a visualization\n",
    "\n",
    "![Specific_Project_1.png MISSING](./images/Specific_Project_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Steps\n",
    " 1. Design a SQL or NoSQL data store to hold analytical data\n",
    "   * Refer to your DSA 8620, Database Analytics, learning\n",
    "   * Plan the data you want to capture, refer to output from module 7 API labs\n",
    " 1. Scrape Reddit RSS into JSON files\n",
    "   * Module 6 exercise\n",
    " 1. Process Files from the Storage Bucket with Natural Language API\n",
    "   * Module 7 labs\n",
    " 1. Pull data from analytical data store and produce\n",
    "   * [Project Step 4 goes in this Notebook, or in a copy of a notebook that you run in the cloud](./exercises/Project.ipynb)\n",
    "   1. aggregate data in tabular format\n",
    "   1. one or more data visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting your work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Steps:\n",
    "  1. Open Terminal in JupyterHub\n",
    "  1. Change into the course folder\n",
    "  1. Stage (Git Add) the module's practive and exercise work   \n",
    "  `git  add   module8/exercises`\n",
    "  1. Create your work snapshot (Git Commit)  \n",
    "  `git   commit   -m   \"Module 8 submission\"`\n",
    "  1. Upload the snapshot to the server (Git Push)  \n",
    "  `git   push`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats you have completed the course!\n",
    "\n",
    "## Note\n",
    "If you foresee cloud computing as part of your future in analytics,\n",
    "it is highly recommended that you redo the project with the second cloud provider.\n",
    "In otherwords, if you did it in AWS, now try it in GCP or vice versa!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
